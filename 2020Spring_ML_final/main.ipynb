{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0zuYQzwiO8Z"
   },
   "source": [
    "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri0oOICuC64e"
   },
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJfG1l3RC_c3"
   },
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "Note: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M9yv4oGGDbmJ",
    "outputId": "de0a4826-3214-4327-9c19-2f73f0dcc13a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acvGcUAaEkxe"
   },
   "source": [
    "Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UcPk4u8qGZHB",
    "outputId": "282049c2-f6f3-4b05-b608-6bebccd908db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "NONE = ['NONE'] # label for empty space\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 7\n",
    "\n",
    "print(ALL_CHAR_SET.index('NONE'))\n",
    "\n",
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot\n",
    "\n",
    "# modified dataset class\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
    "        self.path = img_path\n",
    "        self.label_path = label_path\n",
    "        if is_train: \n",
    "            self.img = os.listdir(self.path)[:1000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
    "        else: \n",
    "            self.img = os.listdir(self.path)[:1000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.max_length = MAX_CAPTCHA\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
    "        img = img.convert('L')\n",
    "        label = self.labels[idx]\n",
    "        label_oh = []\n",
    "        # one-hot for each character\n",
    "        for i in range(self.max_length):\n",
    "            if i < len(label):\n",
    "                label_oh += encode(label[i])\n",
    "            else:\n",
    "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
    "                label_oh += encode('NONE')\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, np.array(label_oh), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([160, 60]),\n",
    "    transforms.ToTensor(),\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "# transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "EFtlQyubGJZb",
    "outputId": "f0349f06-7aba-4294-e904-bd66a654eb05"
   },
   "outputs": [],
   "source": [
    "\"\"\"Loading DATA\"\"\"\n",
    "# Change to your own data folder path!\n",
    "# gPath = '/content/drive/My Drive/Colab Notebooks/'\n",
    "gPath = './'\n",
    "\n",
    "train_ds = Mydataset(gPath+'Data/train/', gPath+'Data/train.txt',transform=transform)\n",
    "test_ds = Mydataset(gPath+'Data/test/', gPath+'Data/test.txt', False, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=128, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka5SgX6VIWcG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"To CUDA for local run\"\"\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "#GPUID = '4' # define GPUID\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJaHW3wSENjY"
   },
   "source": [
    "Problem 1: Design LSTM model for catcha image recognition. (10 points)\n",
    "\n",
    "[Captioning Images with CNN and RNN, using PyTorch](https://medium.com/@stepanulyanin/captioning-images-with-pytorch-bc592e5fd1a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHEe3XmBFQHq"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cnn_dim, hidden_size, vocab_size, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # define the properties\n",
    "        self.cnn_dim = cnn_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # lstm cell\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=self.vocab_size, hidden_size=hidden_size)\n",
    "    \n",
    "        # output fully connected layer\n",
    "        self.fc_in = nn.Linear(in_features=self.cnn_dim, out_features=self.vocab_size)\n",
    "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
    "    \n",
    "        # embedding layer\n",
    "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.vocab_size)\n",
    "    \n",
    "        # activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, features, captions):\n",
    "\n",
    "        batch_size = features.size(0)\n",
    "        cnn_dim = features.size(1)\n",
    "\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "    \n",
    "        # define the output tensor placeholder\n",
    "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).cuda()\n",
    "\n",
    "        # embed the captions\n",
    "        captions_embed = self.embed(captions)\n",
    "        \n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "        # pass the caption word by word\n",
    "        for t in range(captions.size(1)):\n",
    "            # for the first time step the input is the feature vector\n",
    "            if t == 0:\n",
    "                features = features[:, :, 0, 0]\n",
    "                inputs = self.fc_in(features)\n",
    "                hidden_state, cell_state = self.lstm_cell(inputs, (hidden_state, cell_state))\n",
    "                \n",
    "            # for the 2nd+ time step, using teacher forcer\n",
    "            else:\n",
    "                hidden_state, cell_state = self.lstm_cell(captions_embed[:, t, :], (hidden_state, cell_state))\n",
    "            \n",
    "#             print(hidden_state.size())\n",
    "            # output of the attention mechanism\n",
    "            out = self.fc_out(hidden_state)\n",
    "            # build the output tensor\n",
    "            outputs[:, t, :] = out\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "        return outputs[:,:,0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM2vL2PTFeEt"
   },
   "source": [
    "Problem 2: \n",
    "\n",
    "*   1.Connect CNN model to the designed LSTM model.\n",
    "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
    "* https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OwgpQ1aiFq2a",
    "outputId": "61422ea2-c441-4294-ae33-2ed9fe05abf4"
   },
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "# Define a CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 7)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# betternet = Net()\n",
    "\n",
    "\"\"\"ResNet\"\"\"\n",
    "#CNN\n",
    "betternet = resnet.resnet18(pretrained=False)\n",
    "betternet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# betternet.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN, bias=True)\n",
    "betternet.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)\n",
    "betternet = betternet.to(device)\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "\n",
    "       \n",
    "# LSTM\n",
    "cnn_dim=512 #resnet18-512\n",
    "hidden_size=8\n",
    "vocab_size=37 #ALL_CHAR_SET_LEN\n",
    "lstm = LSTM(cnn_dim=cnn_dim, hidden_size=hidden_size, vocab_size=vocab_size)\n",
    "lstm = lstm.to(device)\n",
    "\n",
    "# loss, optimizer\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        \n",
    "    def forward(self, x, captions):\n",
    "        _, feature = self.modelA(x)\n",
    "        pred = self.modelB(feature, captions)\n",
    "        return pred\n",
    "\n",
    "model = MyEnsemble(betternet, lstm)\n",
    "# print(model)\n",
    "\n",
    "# loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "# cnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\n",
    "\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0uCexwRHsNz"
   },
   "source": [
    "Problem3: Find hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "id": "ibfVzKZeH1yC",
    "outputId": "9ec2264f-a93b-4ee3-fcab-87b5292ab8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1 elapsed time: 1.70 sec\n",
      ">> Epoch 2 elapsed time: 1.53 sec\n",
      ">> Epoch 3 elapsed time: 1.51 sec\n",
      ">> Epoch 4 elapsed time: 1.55 sec\n",
      "epoch: 5 step: 1 loss: 0.05884035304188728\n",
      "epoch: 5 step: 2 loss: 0.05680178850889206\n",
      "epoch: 5 step: 3 loss: 0.05481883883476257\n",
      "epoch: 5 step: 4 loss: 0.05292641371488571\n",
      "epoch: 5 step: 5 loss: 0.05106658488512039\n",
      "epoch: 5 step: 6 loss: 0.04943714663386345\n",
      "epoch: 5 step: 7 loss: 0.04787255823612213\n",
      "epoch: 5 step: 8 loss: 0.046319738030433655\n",
      ">> Epoch 5 elapsed time: 1.55 sec\n",
      ">> Epoch 6 elapsed time: 1.47 sec\n",
      ">> Epoch 7 elapsed time: 1.47 sec\n",
      ">> Epoch 8 elapsed time: 1.47 sec\n",
      ">> Epoch 9 elapsed time: 1.48 sec\n",
      "epoch: 10 step: 1 loss: 0.021118484437465668\n",
      "epoch: 10 step: 2 loss: 0.020887982100248337\n",
      "epoch: 10 step: 3 loss: 0.020544061437249184\n",
      "epoch: 10 step: 4 loss: 0.020159199833869934\n",
      "epoch: 10 step: 5 loss: 0.019660821184515953\n",
      "epoch: 10 step: 6 loss: 0.01941952481865883\n",
      "epoch: 10 step: 7 loss: 0.019157398492097855\n",
      "epoch: 10 step: 8 loss: 0.01876315474510193\n",
      ">> Epoch 10 elapsed time: 1.54 sec\n",
      ">> Epoch 11 elapsed time: 1.47 sec\n",
      ">> Epoch 12 elapsed time: 1.48 sec\n",
      ">> Epoch 13 elapsed time: 1.53 sec\n",
      ">> Epoch 14 elapsed time: 1.48 sec\n",
      "epoch: 15 step: 1 loss: 0.01239107921719551\n",
      "epoch: 15 step: 2 loss: 0.012401865795254707\n",
      "epoch: 15 step: 3 loss: 0.012271185405552387\n",
      "epoch: 15 step: 4 loss: 0.01207145769149065\n",
      "epoch: 15 step: 5 loss: 0.011727986857295036\n",
      "epoch: 15 step: 6 loss: 0.011680996045470238\n",
      "epoch: 15 step: 7 loss: 0.01162349060177803\n",
      "epoch: 15 step: 8 loss: 0.01136499922722578\n",
      ">> Epoch 15 elapsed time: 1.55 sec\n",
      ">> Epoch 16 elapsed time: 1.51 sec\n",
      ">> Epoch 17 elapsed time: 1.47 sec\n",
      ">> Epoch 18 elapsed time: 1.50 sec\n",
      ">> Epoch 19 elapsed time: 1.50 sec\n",
      "epoch: 20 step: 1 loss: 0.008435345254838467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucetre/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MyEnsemble. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/lucetre/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 2 loss: 0.008522885851562023\n",
      "epoch: 20 step: 3 loss: 0.008450414054095745\n",
      "epoch: 20 step: 4 loss: 0.008295370265841484\n",
      "epoch: 20 step: 5 loss: 0.007976464927196503\n",
      "epoch: 20 step: 6 loss: 0.007989149540662766\n",
      "epoch: 20 step: 7 loss: 0.007995249703526497\n",
      "epoch: 20 step: 8 loss: 0.007762659806758165\n",
      ">> Epoch 20 elapsed time: 1.92 sec\n",
      ">> Epoch 21 elapsed time: 1.51 sec\n",
      ">> Epoch 22 elapsed time: 1.49 sec\n",
      ">> Epoch 23 elapsed time: 1.48 sec\n",
      ">> Epoch 24 elapsed time: 1.50 sec\n",
      "epoch: 25 step: 1 loss: 0.0055036386474967\n",
      "epoch: 25 step: 2 loss: 0.005624980200082064\n",
      "epoch: 25 step: 3 loss: 0.005569618195295334\n",
      "epoch: 25 step: 4 loss: 0.00542638823390007\n",
      "epoch: 25 step: 5 loss: 0.005104358308017254\n",
      "epoch: 25 step: 6 loss: 0.005145411007106304\n",
      "epoch: 25 step: 7 loss: 0.005182521417737007\n",
      "epoch: 25 step: 8 loss: 0.004957329016178846\n",
      ">> Epoch 25 elapsed time: 1.55 sec\n",
      ">> Epoch 26 elapsed time: 1.48 sec\n",
      ">> Epoch 27 elapsed time: 1.47 sec\n",
      ">> Epoch 28 elapsed time: 1.52 sec\n",
      ">> Epoch 29 elapsed time: 1.52 sec\n",
      "epoch: 30 step: 1 loss: 0.00402288930490613\n",
      "epoch: 30 step: 2 loss: 0.004189168103039265\n",
      "epoch: 30 step: 3 loss: 0.004164414945989847\n",
      "epoch: 30 step: 4 loss: 0.0040447041392326355\n",
      "epoch: 30 step: 5 loss: 0.0037328172475099564\n",
      "epoch: 30 step: 6 loss: 0.003806432243436575\n",
      "epoch: 30 step: 7 loss: 0.003875649766996503\n",
      "epoch: 30 step: 8 loss: 0.0036627002991735935\n",
      ">> Epoch 30 elapsed time: 1.55 sec\n",
      ">> Epoch 31 elapsed time: 1.47 sec\n",
      ">> Epoch 32 elapsed time: 1.48 sec\n",
      ">> Epoch 33 elapsed time: 1.47 sec\n",
      ">> Epoch 34 elapsed time: 1.46 sec\n",
      "epoch: 35 step: 1 loss: 0.003203537780791521\n",
      "epoch: 35 step: 2 loss: 0.0033884630538523197\n",
      "epoch: 35 step: 3 loss: 0.003372106235474348\n",
      "epoch: 35 step: 4 loss: 0.0032559200190007687\n",
      "epoch: 35 step: 5 loss: 0.0029377052560448647\n",
      "epoch: 35 step: 6 loss: 0.003023972734808922\n",
      "epoch: 35 step: 7 loss: 0.003106416668742895\n",
      "epoch: 35 step: 8 loss: 0.002891320502385497\n",
      ">> Epoch 35 elapsed time: 1.55 sec\n",
      ">> Epoch 36 elapsed time: 1.50 sec\n",
      ">> Epoch 37 elapsed time: 1.51 sec\n",
      ">> Epoch 38 elapsed time: 1.48 sec\n",
      ">> Epoch 39 elapsed time: 1.49 sec\n",
      "epoch: 40 step: 1 loss: 0.0026443148963153362\n",
      "epoch: 40 step: 2 loss: 0.0028423878829926252\n",
      "epoch: 40 step: 3 loss: 0.0028307773172855377\n",
      "epoch: 40 step: 4 loss: 0.002715159673243761\n",
      "epoch: 40 step: 5 loss: 0.002389252418652177\n",
      "epoch: 40 step: 6 loss: 0.002484065480530262\n",
      "epoch: 40 step: 7 loss: 0.002575429156422615\n",
      "epoch: 40 step: 8 loss: 0.002356345299631357\n",
      ">> Epoch 40 elapsed time: 1.96 sec\n",
      ">> Epoch 41 elapsed time: 1.46 sec\n",
      ">> Epoch 42 elapsed time: 1.48 sec\n",
      ">> Epoch 43 elapsed time: 1.49 sec\n",
      ">> Epoch 44 elapsed time: 1.49 sec\n",
      "epoch: 45 step: 1 loss: 0.002240701112896204\n",
      "epoch: 45 step: 2 loss: 0.0024490910582244396\n",
      "epoch: 45 step: 3 loss: 0.002440521027892828\n",
      "epoch: 45 step: 4 loss: 0.0023242677561938763\n",
      "epoch: 45 step: 5 loss: 0.0019906279630959034\n",
      "epoch: 45 step: 6 loss: 0.002091809408739209\n",
      "epoch: 45 step: 7 loss: 0.002189969876781106\n",
      "epoch: 45 step: 8 loss: 0.001966442447155714\n",
      ">> Epoch 45 elapsed time: 1.51 sec\n",
      ">> Epoch 46 elapsed time: 1.48 sec\n",
      ">> Epoch 47 elapsed time: 1.45 sec\n",
      ">> Epoch 48 elapsed time: 1.48 sec\n",
      ">> Epoch 49 elapsed time: 1.48 sec\n",
      "epoch: 50 step: 1 loss: 0.0019395733252167702\n",
      "epoch: 50 step: 2 loss: 0.002156400354579091\n",
      "epoch: 50 step: 3 loss: 0.0021498757414519787\n",
      "epoch: 50 step: 4 loss: 0.0020324767101556063\n",
      "epoch: 50 step: 5 loss: 0.001691376673988998\n",
      "epoch: 50 step: 6 loss: 0.0017976071685552597\n",
      "epoch: 50 step: 7 loss: 0.0019010870018973947\n",
      "epoch: 50 step: 8 loss: 0.0016730892239138484\n",
      ">> Epoch 50 elapsed time: 1.53 sec\n",
      ">> Epoch 51 elapsed time: 1.50 sec\n",
      ">> Epoch 52 elapsed time: 1.47 sec\n",
      ">> Epoch 53 elapsed time: 1.51 sec\n",
      ">> Epoch 54 elapsed time: 1.49 sec\n",
      "epoch: 55 step: 1 loss: 0.0017086898442357779\n",
      "epoch: 55 step: 2 loss: 0.001932667102664709\n",
      "epoch: 55 step: 3 loss: 0.0019275761442258954\n",
      "epoch: 55 step: 4 loss: 0.0018086914205923676\n",
      "epoch: 55 step: 5 loss: 0.001460503088310361\n",
      "epoch: 55 step: 6 loss: 0.0015708522405475378\n",
      "epoch: 55 step: 7 loss: 0.001678741187788546\n",
      "epoch: 55 step: 8 loss: 0.0014462866820394993\n",
      ">> Epoch 55 elapsed time: 1.55 sec\n",
      ">> Epoch 56 elapsed time: 1.48 sec\n",
      ">> Epoch 57 elapsed time: 1.48 sec\n",
      ">> Epoch 58 elapsed time: 1.48 sec\n",
      ">> Epoch 59 elapsed time: 1.47 sec\n",
      "epoch: 60 step: 1 loss: 0.0015272063901647925\n",
      "epoch: 60 step: 2 loss: 0.0017573817167431116\n",
      "epoch: 60 step: 3 loss: 0.001753285527229309\n",
      "epoch: 60 step: 4 loss: 0.0016328032361343503\n",
      "epoch: 60 step: 5 loss: 0.001277908100746572\n",
      "epoch: 60 step: 6 loss: 0.0013917569303885102\n",
      "epoch: 60 step: 7 loss: 0.0015033965464681387\n",
      "epoch: 60 step: 8 loss: 0.001266616047360003\n",
      ">> Epoch 60 elapsed time: 1.93 sec\n",
      ">> Epoch 61 elapsed time: 1.46 sec\n",
      ">> Epoch 62 elapsed time: 1.48 sec\n",
      ">> Epoch 63 elapsed time: 1.48 sec\n",
      ">> Epoch 64 elapsed time: 1.54 sec\n",
      "epoch: 65 step: 1 loss: 0.0013814391568303108\n",
      "epoch: 65 step: 2 loss: 0.0016171110328286886\n",
      "epoch: 65 step: 3 loss: 0.001613749423995614\n",
      "epoch: 65 step: 4 loss: 0.0014916457002982497\n",
      "epoch: 65 step: 5 loss: 0.001130373915657401\n",
      "epoch: 65 step: 6 loss: 0.0012472905218601227\n",
      "epoch: 65 step: 7 loss: 0.0013621121179312468\n",
      "epoch: 65 step: 8 loss: 0.0011212847894057631\n",
      ">> Epoch 65 elapsed time: 1.55 sec\n",
      ">> Epoch 66 elapsed time: 1.52 sec\n",
      ">> Epoch 67 elapsed time: 1.49 sec\n",
      ">> Epoch 68 elapsed time: 1.47 sec\n",
      ">> Epoch 69 elapsed time: 1.49 sec\n",
      "epoch: 70 step: 1 loss: 0.0012622789945453405\n",
      "epoch: 70 step: 2 loss: 0.0015028567286208272\n",
      "epoch: 70 step: 3 loss: 0.0015001163119450212\n",
      "epoch: 70 step: 4 loss: 0.0013763431925326586\n",
      "epoch: 70 step: 5 loss: 0.001009128405712545\n",
      "epoch: 70 step: 6 loss: 0.0011286836815997958\n",
      "epoch: 70 step: 7 loss: 0.0012463585007935762\n",
      "epoch: 70 step: 8 loss: 0.0010016743326559663\n",
      ">> Epoch 70 elapsed time: 1.53 sec\n",
      ">> Epoch 71 elapsed time: 1.48 sec\n",
      ">> Epoch 72 elapsed time: 1.50 sec\n",
      ">> Epoch 73 elapsed time: 1.53 sec\n",
      ">> Epoch 74 elapsed time: 1.47 sec\n",
      "epoch: 75 step: 1 loss: 0.001163419452495873\n",
      "epoch: 75 step: 2 loss: 0.0014084887225180864\n",
      "epoch: 75 step: 3 loss: 0.0014061587862670422\n",
      "epoch: 75 step: 4 loss: 0.0012808232568204403\n",
      "epoch: 75 step: 5 loss: 0.0009079359006136656\n",
      "epoch: 75 step: 6 loss: 0.0010299362475052476\n",
      "epoch: 75 step: 7 loss: 0.0011501060798764229\n",
      "epoch: 75 step: 8 loss: 0.0009017266565933824\n",
      ">> Epoch 75 elapsed time: 1.53 sec\n",
      ">> Epoch 76 elapsed time: 1.51 sec\n",
      ">> Epoch 77 elapsed time: 1.51 sec\n",
      ">> Epoch 78 elapsed time: 1.49 sec\n",
      ">> Epoch 79 elapsed time: 1.49 sec\n",
      "epoch: 80 step: 1 loss: 0.0010804067132994533\n",
      "epoch: 80 step: 2 loss: 0.0013295349199324846\n",
      "epoch: 80 step: 3 loss: 0.0013275903183966875\n",
      "epoch: 80 step: 4 loss: 0.0012006557080894709\n",
      "epoch: 80 step: 5 loss: 0.000822479953058064\n",
      "epoch: 80 step: 6 loss: 0.0009466272313147783\n",
      "epoch: 80 step: 7 loss: 0.0010691097704693675\n",
      "epoch: 80 step: 8 loss: 0.0008172258385457098\n",
      ">> Epoch 80 elapsed time: 1.93 sec\n",
      ">> Epoch 81 elapsed time: 1.50 sec\n",
      ">> Epoch 82 elapsed time: 1.46 sec\n",
      ">> Epoch 83 elapsed time: 1.50 sec\n",
      ">> Epoch 84 elapsed time: 1.48 sec\n",
      "epoch: 85 step: 1 loss: 0.0010098153725266457\n",
      "epoch: 85 step: 2 loss: 0.0012627620017156005\n",
      "epoch: 85 step: 3 loss: 0.0012610949343070388\n",
      "epoch: 85 step: 4 loss: 0.0011326372623443604\n",
      "epoch: 85 step: 5 loss: 0.0007494969759136438\n",
      "epoch: 85 step: 6 loss: 0.000875617319252342\n",
      "epoch: 85 step: 7 loss: 0.0010002544149756432\n",
      "epoch: 85 step: 8 loss: 0.0007450265693478286\n",
      ">> Epoch 85 elapsed time: 1.52 sec\n",
      ">> Epoch 86 elapsed time: 1.48 sec\n",
      ">> Epoch 87 elapsed time: 1.47 sec\n",
      ">> Epoch 88 elapsed time: 1.47 sec\n",
      ">> Epoch 89 elapsed time: 1.48 sec\n",
      "epoch: 90 step: 1 loss: 0.0009493448305875063\n",
      "epoch: 90 step: 2 loss: 0.0012057931162416935\n",
      "epoch: 90 step: 3 loss: 0.0012043715687468648\n",
      "epoch: 90 step: 4 loss: 0.0010744612663984299\n",
      "epoch: 90 step: 5 loss: 0.0006865743780508637\n",
      "epoch: 90 step: 6 loss: 0.0008145326864905655\n",
      "epoch: 90 step: 7 loss: 0.0009410703787580132\n",
      "epoch: 90 step: 8 loss: 0.0006827377947047353\n",
      ">> Epoch 90 elapsed time: 1.52 sec\n",
      ">> Epoch 91 elapsed time: 1.48 sec\n",
      ">> Epoch 92 elapsed time: 1.47 sec\n",
      ">> Epoch 93 elapsed time: 1.45 sec\n",
      ">> Epoch 94 elapsed time: 1.47 sec\n",
      "epoch: 95 step: 1 loss: 0.0008970504277385771\n",
      "epoch: 95 step: 2 loss: 0.0011568032205104828\n",
      "epoch: 95 step: 3 loss: 0.001155524281784892\n",
      "epoch: 95 step: 4 loss: 0.0010242790449410677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 step: 5 loss: 0.0006318388623185456\n",
      "epoch: 95 step: 6 loss: 0.0007615217473357916\n",
      "epoch: 95 step: 7 loss: 0.0008899061940610409\n",
      "epoch: 95 step: 8 loss: 0.0006285595009103417\n",
      ">> Epoch 95 elapsed time: 1.51 sec\n",
      ">> Epoch 96 elapsed time: 1.47 sec\n",
      ">> Epoch 97 elapsed time: 1.50 sec\n",
      ">> Epoch 98 elapsed time: 1.48 sec\n",
      ">> Epoch 99 elapsed time: 1.46 sec\n",
      "epoch: 100 step: 1 loss: 0.0008514835499227047\n",
      "epoch: 100 step: 2 loss: 0.001114341663196683\n",
      "epoch: 100 step: 3 loss: 0.0011132261715829372\n",
      "epoch: 100 step: 4 loss: 0.0009806037414819002\n",
      "epoch: 100 step: 5 loss: 0.0005839273799210787\n",
      "epoch: 100 step: 6 loss: 0.0007152111502364278\n",
      "epoch: 100 step: 7 loss: 0.0008452226174995303\n",
      "epoch: 100 step: 8 loss: 0.0005810665315948427\n",
      ">> Epoch 100 elapsed time: 1.93 sec\n",
      ">> Epoch 101 elapsed time: 1.46 sec\n",
      ">> Epoch 102 elapsed time: 1.47 sec\n",
      ">> Epoch 103 elapsed time: 1.47 sec\n",
      ">> Epoch 104 elapsed time: 1.47 sec\n",
      "epoch: 105 step: 1 loss: 0.0008115405216813087\n",
      "epoch: 105 step: 2 loss: 0.0010773190297186375\n",
      "epoch: 105 step: 3 loss: 0.0010762907331809402\n",
      "epoch: 105 step: 4 loss: 0.000942444137763232\n",
      "epoch: 105 step: 5 loss: 0.0005418061628006399\n",
      "epoch: 105 step: 6 loss: 0.000674524693749845\n",
      "epoch: 105 step: 7 loss: 0.000806083669885993\n",
      "epoch: 105 step: 8 loss: 0.0005392871680669487\n",
      ">> Epoch 105 elapsed time: 1.50 sec\n",
      ">> Epoch 106 elapsed time: 1.47 sec\n",
      ">> Epoch 107 elapsed time: 1.48 sec\n",
      ">> Epoch 108 elapsed time: 1.46 sec\n",
      ">> Epoch 109 elapsed time: 1.47 sec\n",
      "epoch: 110 step: 1 loss: 0.000776318134739995\n",
      "epoch: 110 step: 2 loss: 0.0010448128450661898\n",
      "epoch: 110 step: 3 loss: 0.0010439259931445122\n",
      "epoch: 110 step: 4 loss: 0.0009087738581001759\n",
      "epoch: 110 step: 5 loss: 0.0005045518046244979\n",
      "epoch: 110 step: 6 loss: 0.0006384465377777815\n",
      "epoch: 110 step: 7 loss: 0.0007714640814810991\n",
      "epoch: 110 step: 8 loss: 0.000502140901517123\n",
      ">> Epoch 110 elapsed time: 1.52 sec\n",
      ">> Epoch 111 elapsed time: 1.47 sec\n",
      ">> Epoch 112 elapsed time: 1.49 sec\n",
      ">> Epoch 113 elapsed time: 1.47 sec\n",
      ">> Epoch 114 elapsed time: 1.46 sec\n",
      "epoch: 115 step: 1 loss: 0.0007451577112078667\n",
      "epoch: 115 step: 2 loss: 0.0010163425467908382\n",
      "epoch: 115 step: 3 loss: 0.0010155222844332457\n",
      "epoch: 115 step: 4 loss: 0.0008792260196059942\n",
      "epoch: 115 step: 5 loss: 0.0004708524502348155\n",
      "epoch: 115 step: 6 loss: 0.0006064235931262374\n",
      "epoch: 115 step: 7 loss: 0.0007408352685160935\n",
      "epoch: 115 step: 8 loss: 0.00046894693514332175\n",
      ">> Epoch 115 elapsed time: 1.51 sec\n",
      ">> Epoch 116 elapsed time: 1.47 sec\n",
      ">> Epoch 117 elapsed time: 1.47 sec\n",
      ">> Epoch 118 elapsed time: 1.48 sec\n",
      ">> Epoch 119 elapsed time: 1.46 sec\n",
      "epoch: 120 step: 1 loss: 0.0007173377089202404\n",
      "epoch: 120 step: 2 loss: 0.0009909674990922213\n",
      "epoch: 120 step: 3 loss: 0.0009902771562337875\n",
      "epoch: 120 step: 4 loss: 0.0008528140606358647\n",
      "epoch: 120 step: 5 loss: 0.0004409624671097845\n",
      "epoch: 120 step: 6 loss: 0.0005777581827715039\n",
      "epoch: 120 step: 7 loss: 0.0007135369814932346\n",
      "epoch: 120 step: 8 loss: 0.00043919755262322724\n",
      ">> Epoch 120 elapsed time: 1.93 sec\n",
      ">> Epoch 121 elapsed time: 1.47 sec\n",
      ">> Epoch 122 elapsed time: 1.49 sec\n",
      ">> Epoch 123 elapsed time: 1.49 sec\n",
      ">> Epoch 124 elapsed time: 1.47 sec\n",
      "epoch: 125 step: 1 loss: 0.0006924557965248823\n",
      "epoch: 125 step: 2 loss: 0.0009684342658147216\n",
      "epoch: 125 step: 3 loss: 0.0009678234346210957\n",
      "epoch: 125 step: 4 loss: 0.000829279946628958\n",
      "epoch: 125 step: 5 loss: 0.00041402154602110386\n",
      "epoch: 125 step: 6 loss: 0.0005519933765754104\n",
      "epoch: 125 step: 7 loss: 0.0006890021031722426\n",
      "epoch: 125 step: 8 loss: 0.00041246210457757115\n",
      ">> Epoch 125 elapsed time: 1.52 sec\n",
      ">> Epoch 126 elapsed time: 1.46 sec\n",
      ">> Epoch 127 elapsed time: 1.48 sec\n",
      ">> Epoch 128 elapsed time: 1.45 sec\n",
      ">> Epoch 129 elapsed time: 1.48 sec\n",
      "epoch: 130 step: 1 loss: 0.0006701208767481148\n",
      "epoch: 130 step: 2 loss: 0.0009483132744207978\n",
      "epoch: 130 step: 3 loss: 0.0009477831772528589\n",
      "epoch: 130 step: 4 loss: 0.0008081365376710892\n",
      "epoch: 130 step: 5 loss: 0.0003897016285918653\n",
      "epoch: 130 step: 6 loss: 0.0005287975072860718\n",
      "epoch: 130 step: 7 loss: 0.0006670369184575975\n",
      "epoch: 130 step: 8 loss: 0.00038830217090435326\n",
      ">> Epoch 130 elapsed time: 1.53 sec\n",
      ">> Epoch 131 elapsed time: 1.47 sec\n",
      ">> Epoch 132 elapsed time: 1.44 sec\n",
      ">> Epoch 133 elapsed time: 1.47 sec\n",
      ">> Epoch 134 elapsed time: 1.48 sec\n",
      "epoch: 135 step: 1 loss: 0.0006499544833786786\n",
      "epoch: 135 step: 2 loss: 0.0009302867110818624\n",
      "epoch: 135 step: 3 loss: 0.0009297830983996391\n",
      "epoch: 135 step: 4 loss: 0.0007891820278018713\n",
      "epoch: 135 step: 5 loss: 0.0003676010819617659\n",
      "epoch: 135 step: 6 loss: 0.0005078000831417739\n",
      "epoch: 135 step: 7 loss: 0.0006471432279795408\n",
      "epoch: 135 step: 8 loss: 0.00036639944300986826\n",
      ">> Epoch 135 elapsed time: 1.53 sec\n",
      ">> Epoch 136 elapsed time: 1.48 sec\n",
      ">> Epoch 137 elapsed time: 1.49 sec\n",
      ">> Epoch 138 elapsed time: 1.45 sec\n",
      ">> Epoch 139 elapsed time: 1.48 sec\n",
      "epoch: 140 step: 1 loss: 0.0006317145889624953\n",
      "epoch: 140 step: 2 loss: 0.0009141422342509031\n",
      "epoch: 140 step: 3 loss: 0.0009136106818914413\n",
      "epoch: 140 step: 4 loss: 0.0007720193825662136\n",
      "epoch: 140 step: 5 loss: 0.00034748794860206544\n",
      "epoch: 140 step: 6 loss: 0.0004887426039204001\n",
      "epoch: 140 step: 7 loss: 0.000629144546110183\n",
      "epoch: 140 step: 8 loss: 0.00034640036756172776\n",
      ">> Epoch 140 elapsed time: 1.91 sec\n",
      ">> Epoch 141 elapsed time: 1.47 sec\n",
      ">> Epoch 142 elapsed time: 1.48 sec\n",
      ">> Epoch 143 elapsed time: 1.47 sec\n",
      ">> Epoch 144 elapsed time: 1.47 sec\n",
      "epoch: 145 step: 1 loss: 0.0006150908884592354\n",
      "epoch: 145 step: 2 loss: 0.0008994669187813997\n",
      "epoch: 145 step: 3 loss: 0.0008990562637336552\n",
      "epoch: 145 step: 4 loss: 0.0007565649575553834\n",
      "epoch: 145 step: 5 loss: 0.00032917270436882973\n",
      "epoch: 145 step: 6 loss: 0.0004713970993179828\n",
      "epoch: 145 step: 7 loss: 0.0006128125824034214\n",
      "epoch: 145 step: 8 loss: 0.00032815273152664304\n",
      ">> Epoch 145 elapsed time: 1.51 sec\n",
      ">> Epoch 146 elapsed time: 1.45 sec\n",
      ">> Epoch 147 elapsed time: 1.48 sec\n",
      ">> Epoch 148 elapsed time: 1.48 sec\n",
      ">> Epoch 149 elapsed time: 1.45 sec\n",
      "epoch: 150 step: 1 loss: 0.000600008643232286\n",
      "epoch: 150 step: 2 loss: 0.0008862509857863188\n",
      "epoch: 150 step: 3 loss: 0.0008858829969540238\n",
      "epoch: 150 step: 4 loss: 0.0007424757350236177\n",
      "epoch: 150 step: 5 loss: 0.00031233986373990774\n",
      "epoch: 150 step: 6 loss: 0.00045549555215984583\n",
      "epoch: 150 step: 7 loss: 0.000597906531766057\n",
      "epoch: 150 step: 8 loss: 0.00031145004322752357\n",
      ">> Epoch 150 elapsed time: 1.54 sec\n",
      ">> Epoch 151 elapsed time: 1.47 sec\n",
      ">> Epoch 152 elapsed time: 1.47 sec\n",
      ">> Epoch 153 elapsed time: 1.48 sec\n",
      ">> Epoch 154 elapsed time: 1.47 sec\n",
      "epoch: 155 step: 1 loss: 0.000586239097174257\n",
      "epoch: 155 step: 2 loss: 0.0008742604404687881\n",
      "epoch: 155 step: 3 loss: 0.0008739490294829011\n",
      "epoch: 155 step: 4 loss: 0.000729632331058383\n",
      "epoch: 155 step: 5 loss: 0.0002968712942674756\n",
      "epoch: 155 step: 6 loss: 0.0004409912507981062\n",
      "epoch: 155 step: 7 loss: 0.0005842950195074081\n",
      "epoch: 155 step: 8 loss: 0.0002961079590022564\n",
      ">> Epoch 155 elapsed time: 1.54 sec\n",
      ">> Epoch 156 elapsed time: 1.48 sec\n",
      ">> Epoch 157 elapsed time: 1.48 sec\n",
      ">> Epoch 158 elapsed time: 1.48 sec\n",
      ">> Epoch 159 elapsed time: 1.46 sec\n",
      "epoch: 160 step: 1 loss: 0.0005735958693549037\n",
      "epoch: 160 step: 2 loss: 0.0008634102414362133\n",
      "epoch: 160 step: 3 loss: 0.0008630298543721437\n",
      "epoch: 160 step: 4 loss: 0.0007179612293839455\n",
      "epoch: 160 step: 5 loss: 0.0002826511627063155\n",
      "epoch: 160 step: 6 loss: 0.0004276384424883872\n",
      "epoch: 160 step: 7 loss: 0.0005718287429772317\n",
      "epoch: 160 step: 8 loss: 0.00028193817706778646\n",
      ">> Epoch 160 elapsed time: 1.89 sec\n",
      ">> Epoch 161 elapsed time: 1.45 sec\n",
      ">> Epoch 162 elapsed time: 1.45 sec\n",
      ">> Epoch 163 elapsed time: 1.46 sec\n",
      ">> Epoch 164 elapsed time: 1.44 sec\n",
      "epoch: 165 step: 1 loss: 0.0005619970033876598\n",
      "epoch: 165 step: 2 loss: 0.0008534545777365565\n",
      "epoch: 165 step: 3 loss: 0.0008531758794561028\n",
      "epoch: 165 step: 4 loss: 0.000707209634128958\n",
      "epoch: 165 step: 5 loss: 0.0002695457951631397\n",
      "epoch: 165 step: 6 loss: 0.00041530653834342957\n",
      "epoch: 165 step: 7 loss: 0.0005603995523415506\n",
      "epoch: 165 step: 8 loss: 0.0002688766981009394\n",
      ">> Epoch 165 elapsed time: 1.52 sec\n",
      ">> Epoch 166 elapsed time: 1.52 sec\n",
      ">> Epoch 167 elapsed time: 1.64 sec\n",
      ">> Epoch 168 elapsed time: 1.51 sec\n",
      ">> Epoch 169 elapsed time: 1.67 sec\n",
      "epoch: 170 step: 1 loss: 0.0005513657815754414\n",
      "epoch: 170 step: 2 loss: 0.0008444057311862707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 step: 3 loss: 0.0008440653327852488\n",
      "epoch: 170 step: 4 loss: 0.000697401468642056\n",
      "epoch: 170 step: 5 loss: 0.000257396895904094\n",
      "epoch: 170 step: 6 loss: 0.0004039922496303916\n",
      "epoch: 170 step: 7 loss: 0.0005498526152223349\n",
      "epoch: 170 step: 8 loss: 0.0002567602205090225\n",
      ">> Epoch 170 elapsed time: 1.70 sec\n",
      ">> Epoch 171 elapsed time: 1.52 sec\n",
      ">> Epoch 172 elapsed time: 1.50 sec\n",
      ">> Epoch 173 elapsed time: 1.51 sec\n",
      ">> Epoch 174 elapsed time: 1.51 sec\n",
      "epoch: 175 step: 1 loss: 0.0005415061605162919\n",
      "epoch: 175 step: 2 loss: 0.0008360549109056592\n",
      "epoch: 175 step: 3 loss: 0.0008358012419193983\n",
      "epoch: 175 step: 4 loss: 0.0006883914466015995\n",
      "epoch: 175 step: 5 loss: 0.00024613464483991265\n",
      "epoch: 175 step: 6 loss: 0.00039349141297861934\n",
      "epoch: 175 step: 7 loss: 0.0005401350790634751\n",
      "epoch: 175 step: 8 loss: 0.0002455268404446542\n",
      ">> Epoch 175 elapsed time: 1.52 sec\n",
      ">> Epoch 176 elapsed time: 1.49 sec\n",
      ">> Epoch 177 elapsed time: 1.48 sec\n",
      ">> Epoch 178 elapsed time: 1.48 sec\n",
      ">> Epoch 179 elapsed time: 1.47 sec\n",
      "epoch: 180 step: 1 loss: 0.0005324269877746701\n",
      "epoch: 180 step: 2 loss: 0.0008284309878945351\n",
      "epoch: 180 step: 3 loss: 0.0008281860500574112\n",
      "epoch: 180 step: 4 loss: 0.0006800568662583828\n",
      "epoch: 180 step: 5 loss: 0.00023563308059237897\n",
      "epoch: 180 step: 6 loss: 0.0003837106341961771\n",
      "epoch: 180 step: 7 loss: 0.0005311862332746387\n",
      "epoch: 180 step: 8 loss: 0.00023513886844739318\n",
      ">> Epoch 180 elapsed time: 1.90 sec\n",
      ">> Epoch 181 elapsed time: 1.48 sec\n",
      ">> Epoch 182 elapsed time: 1.45 sec\n",
      ">> Epoch 183 elapsed time: 1.47 sec\n",
      ">> Epoch 184 elapsed time: 1.48 sec\n",
      "epoch: 185 step: 1 loss: 0.0005240556783974171\n",
      "epoch: 185 step: 2 loss: 0.0008214772678911686\n",
      "epoch: 185 step: 3 loss: 0.0008212459506466985\n",
      "epoch: 185 step: 4 loss: 0.0006724252016283572\n",
      "epoch: 185 step: 5 loss: 0.0002259177854284644\n",
      "epoch: 185 step: 6 loss: 0.0003746958973351866\n",
      "epoch: 185 step: 7 loss: 0.0005228907102718949\n",
      "epoch: 185 step: 8 loss: 0.0002254432620247826\n",
      ">> Epoch 185 elapsed time: 1.52 sec\n",
      ">> Epoch 186 elapsed time: 1.48 sec\n",
      ">> Epoch 187 elapsed time: 1.48 sec\n",
      ">> Epoch 188 elapsed time: 1.47 sec\n",
      ">> Epoch 189 elapsed time: 1.50 sec\n",
      "epoch: 190 step: 1 loss: 0.0005162392626516521\n",
      "epoch: 190 step: 2 loss: 0.0008150158682838082\n",
      "epoch: 190 step: 3 loss: 0.0008147893822751939\n",
      "epoch: 190 step: 4 loss: 0.0006652986630797386\n",
      "epoch: 190 step: 5 loss: 0.0002167881466448307\n",
      "epoch: 190 step: 6 loss: 0.00036624251515604556\n",
      "epoch: 190 step: 7 loss: 0.0005151282530277967\n",
      "epoch: 190 step: 8 loss: 0.0002163345634471625\n",
      ">> Epoch 190 elapsed time: 1.52 sec\n",
      ">> Epoch 191 elapsed time: 1.50 sec\n",
      ">> Epoch 192 elapsed time: 1.50 sec\n",
      ">> Epoch 193 elapsed time: 1.54 sec\n",
      ">> Epoch 194 elapsed time: 1.47 sec\n",
      "epoch: 195 step: 1 loss: 0.0005090028280392289\n",
      "epoch: 195 step: 2 loss: 0.0008090729243122041\n",
      "epoch: 195 step: 3 loss: 0.0008088600588962436\n",
      "epoch: 195 step: 4 loss: 0.0006587298703379929\n",
      "epoch: 195 step: 5 loss: 0.00020828493870794773\n",
      "epoch: 195 step: 6 loss: 0.0003583893703762442\n",
      "epoch: 195 step: 7 loss: 0.0005079430993646383\n",
      "epoch: 195 step: 8 loss: 0.00020786812820006162\n",
      ">> Epoch 195 elapsed time: 1.56 sec\n",
      ">> Epoch 196 elapsed time: 1.48 sec\n",
      ">> Epoch 197 elapsed time: 1.52 sec\n",
      ">> Epoch 198 elapsed time: 1.47 sec\n",
      ">> Epoch 199 elapsed time: 1.47 sec\n",
      "epoch: 200 step: 1 loss: 0.0005022335681132972\n",
      "epoch: 200 step: 2 loss: 0.000803554430603981\n",
      "epoch: 200 step: 3 loss: 0.0008033519261516631\n",
      "epoch: 200 step: 4 loss: 0.0006526061915792525\n",
      "epoch: 200 step: 5 loss: 0.00020038190996274352\n",
      "epoch: 200 step: 6 loss: 0.0003511010145302862\n",
      "epoch: 200 step: 7 loss: 0.0005012894980609417\n",
      "epoch: 200 step: 8 loss: 0.00019996394985355437\n",
      ">> Epoch 200 elapsed time: 1.91 sec\n",
      "Total Elapsed Time: 302.93 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"TRAINING\"\"\"\n",
    "print_interval = 5\n",
    "max_epoch = 200\n",
    "\n",
    "x_labels = []\n",
    "y_labels = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(max_epoch):\n",
    "    start_epoch_time = time.time()\n",
    "    for step, i in enumerate(train_dl):\n",
    "        start_step_time = time.time()\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.long()).cuda()\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "        batch_size, _ = label_oh.shape\n",
    "    \n",
    "#         pred, feature = betternet(img)\n",
    "#         loss = loss_func(pred, label_oh)\n",
    "#         cnn_optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         cnn_optim.step()  \n",
    "        \n",
    "        pred = model(img, label_oh)\n",
    "        loss = loss_func(pred, label_oh)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "        if (epoch+1)%print_interval == 0:\n",
    "            print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())\n",
    "            y_labels.append(loss.item())\n",
    "            x_labels.append('epoch:{}, step:{}'.format(epoch+1, step+1))\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            torch.save(model, './models/BetterNet_LSTM_epoch{}.pth'.format(epoch+1))\n",
    "    print('>> Epoch', epoch+1, 'elapsed time: {:.2f} sec'.format(time.time()-start_epoch_time))\n",
    "print('Total Elapsed Time: {:.2f} sec'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_labels)\n",
    "plt.xlabel('iteration (steps)')\n",
    "plt.ylabel('multi label loss')\n",
    "plt.title('BetterNet+LSTM Training Error')\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('BetterNet+LSTM.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e_uKOpe8IGJk",
    "outputId": "1b5ae24d-d2aa-4080-97ad-a9a064a552c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: b9x____ , LABEL: b9x____\n",
      "PREDICT: mb_____ , LABEL: mb_____\n",
      "PREDICT: d5q7qh_ , LABEL: d5q7qh_\n",
      "PREDICT: 6tl0kqv , LABEL: 6tl0kqv\n",
      "PREDICT: t1_____ , LABEL: t1_____\n",
      "PREDICT: avhjn3z , LABEL: avhjn3z\n",
      "PREDICT: 74z0z__ , LABEL: 74z0z__\n",
      "PREDICT: f1kfa__ , LABEL: f1kfa__\n",
      "PREDICT: sripns_ , LABEL: sripns_\n",
      "PREDICT: bg4____ , LABEL: bg4____\n",
      "PREDICT: gmb45tz , LABEL: gmb45tz\n",
      "PREDICT: sr5____ , LABEL: sr5____\n",
      "PREDICT: 0nt____ , LABEL: 0nt____\n",
      "PREDICT: lxfg98_ , LABEL: lxfg98_\n",
      "PREDICT: 2b8o___ , LABEL: 2b8o___\n",
      "PREDICT: kr25___ , LABEL: kr25___\n",
      "PREDICT: fl_____ , LABEL: fl_____\n",
      "PREDICT: 0tiwrd_ , LABEL: 0tiwrd_\n",
      "PREDICT: k5_____ , LABEL: k5_____\n",
      "PREDICT: 8k_____ , LABEL: 8k_____\n",
      "PREDICT: ggin___ , LABEL: ggin___\n",
      "PREDICT: qc6e___ , LABEL: qc6e___\n",
      "PREDICT: giz6rv_ , LABEL: giz6rv_\n",
      "PREDICT: tf15___ , LABEL: tf15___\n",
      "PREDICT: 7jz____ , LABEL: 7jz____\n",
      "PREDICT: v3zl9__ , LABEL: v3zl9__\n",
      "PREDICT: p78ec__ , LABEL: p78ec__\n",
      "PREDICT: 7rh____ , LABEL: 7rh____\n",
      "PREDICT: exqo___ , LABEL: exqo___\n",
      "PREDICT: yrs____ , LABEL: yrs____\n",
      "PREDICT: si_____ , LABEL: si_____\n",
      "PREDICT: n4tikm_ , LABEL: n4tikm_\n",
      "PREDICT: l2c8p__ , LABEL: l2c8p__\n",
      "PREDICT: fixf___ , LABEL: fixf___\n",
      "PREDICT: d0j1f__ , LABEL: d0j1f__\n",
      "PREDICT: higm___ , LABEL: higm___\n",
      "PREDICT: 3qty___ , LABEL: 3qty___\n",
      "PREDICT: lnw____ , LABEL: lnw____\n",
      "PREDICT: kid92__ , LABEL: kid92__\n",
      "PREDICT: fg_____ , LABEL: fg_____\n",
      "PREDICT: 7u0____ , LABEL: 7u0____\n",
      "PREDICT: qbd____ , LABEL: qbd____\n",
      "PREDICT: ofb____ , LABEL: ofb____\n",
      "PREDICT: zdn____ , LABEL: zdn____\n",
      "PREDICT: sqvrc__ , LABEL: sqvrc__\n",
      "PREDICT: xyx2z1_ , LABEL: xyx2z1_\n",
      "PREDICT: bcdbx__ , LABEL: bcdbx__\n",
      "PREDICT: ejt____ , LABEL: ejt____\n",
      "PREDICT: tl1z___ , LABEL: tl1z___\n",
      "PREDICT: pn_____ , LABEL: pn_____\n",
      "PREDICT: 2l_____ , LABEL: 2l_____\n",
      "PREDICT: 5aip1__ , LABEL: 5aip1__\n",
      "PREDICT: 8l5pw__ , LABEL: 8l5pw__\n",
      "PREDICT: q7u____ , LABEL: q7u____\n",
      "PREDICT: ht1kc5_ , LABEL: ht1kc5_\n",
      "PREDICT: lpxdssw , LABEL: lpxdssw\n",
      "PREDICT: hweg1gz , LABEL: hweg1gz\n",
      "PREDICT: ie_____ , LABEL: ie_____\n",
      "PREDICT: my_____ , LABEL: my_____\n",
      "PREDICT: qfcmgzd , LABEL: qfcmgzd\n",
      "PREDICT: kfozxb_ , LABEL: kfozxb_\n",
      "PREDICT: ip_____ , LABEL: ip_____\n",
      "PREDICT: d3a0___ , LABEL: d3a0___\n",
      "PREDICT: z8359__ , LABEL: z8359__\n",
      "PREDICT: 8cu____ , LABEL: 8cu____\n",
      "PREDICT: mjnjd99 , LABEL: mjnjd99\n",
      "PREDICT: ln_____ , LABEL: ln_____\n",
      "PREDICT: huet___ , LABEL: huet___\n",
      "PREDICT: ahgjju_ , LABEL: ahgjju_\n",
      "PREDICT: 3m9h___ , LABEL: 3m9h___\n",
      "PREDICT: 2n_____ , LABEL: 2n_____\n",
      "PREDICT: edcui9_ , LABEL: edcui9_\n",
      "PREDICT: r3ifo__ , LABEL: r3ifo__\n",
      "PREDICT: 85280__ , LABEL: 85280__\n",
      "PREDICT: 29jxiz_ , LABEL: 29jxiz_\n",
      "PREDICT: 5kxn1q7 , LABEL: 5kxn1q7\n",
      "PREDICT: 54yb7q_ , LABEL: 54yb7q_\n",
      "PREDICT: bv61bpv , LABEL: bv61bpv\n",
      "PREDICT: okg____ , LABEL: okg____\n",
      "PREDICT: y2x1___ , LABEL: y2x1___\n",
      "PREDICT: 6nuuuct , LABEL: 6nuuuct\n",
      "PREDICT: f8m2rf_ , LABEL: f8m2rf_\n",
      "PREDICT: lh_____ , LABEL: lh_____\n",
      "PREDICT: o6ekils , LABEL: o6ekils\n",
      "PREDICT: smbyyr_ , LABEL: smbyyr_\n",
      "PREDICT: 5q_____ , LABEL: 5q_____\n",
      "PREDICT: 976dq__ , LABEL: 976dq__\n",
      "PREDICT: edvbd__ , LABEL: edvbd__\n",
      "PREDICT: p3il___ , LABEL: p3il___\n",
      "PREDICT: wdzlz__ , LABEL: wdzlz__\n",
      "PREDICT: h0e____ , LABEL: h0e____\n",
      "PREDICT: 01_____ , LABEL: 01_____\n",
      "PREDICT: wtr____ , LABEL: wtr____\n",
      "PREDICT: 2ye9wrw , LABEL: 2ye9wrw\n",
      "PREDICT: 3g_____ , LABEL: 3g_____\n",
      "PREDICT: avvo___ , LABEL: avvo___\n",
      "PREDICT: g6s____ , LABEL: g6s____\n",
      "PREDICT: lprk___ , LABEL: lprk___\n",
      "PREDICT: 95hqkv_ , LABEL: 95hqkv_\n",
      "PREDICT: 8gqu2__ , LABEL: 8gqu2__\n",
      "PREDICT: 664ot5_ , LABEL: 664ot5_\n",
      "PREDICT: c9_____ , LABEL: c9_____\n",
      "PREDICT: qw3xkwb , LABEL: qw3xkwb\n",
      "PREDICT: zyjh___ , LABEL: zyjh___\n",
      "PREDICT: 0e_____ , LABEL: 0e_____\n",
      "PREDICT: 6uzkr__ , LABEL: 6uzkr__\n",
      "PREDICT: 68_____ , LABEL: 68_____\n",
      "PREDICT: cpcmx__ , LABEL: cpcmx__\n",
      "PREDICT: ieox4l_ , LABEL: ieox4l_\n",
      "PREDICT: 6pv3h__ , LABEL: 6pv3h__\n",
      "PREDICT: kl_____ , LABEL: kl_____\n",
      "PREDICT: 2b_____ , LABEL: 2b_____\n",
      "PREDICT: 1vwr6bc , LABEL: 1vwr6bc\n",
      "PREDICT: xh9kp6i , LABEL: xh9kp6i\n",
      "PREDICT: rz_____ , LABEL: rz_____\n",
      "PREDICT: h9gqvfp , LABEL: h9gqvfp\n",
      "PREDICT: asq5bk_ , LABEL: asq5bk_\n",
      "PREDICT: 5e_____ , LABEL: 5e_____\n",
      "PREDICT: n1w9___ , LABEL: n1w9___\n",
      "PREDICT: rkfqsac , LABEL: rkfqsac\n",
      "PREDICT: 5uc____ , LABEL: 5uc____\n",
      "PREDICT: zj6zw__ , LABEL: zj6zw__\n",
      "PREDICT: e6zi___ , LABEL: e6zi___\n",
      "PREDICT: fi9ucm8 , LABEL: fi9ucm8\n",
      "PREDICT: g5g8a7_ , LABEL: g5g8a7_\n",
      "PREDICT: larv___ , LABEL: larv___\n",
      "PREDICT: y6_____ , LABEL: y6_____\n",
      "PREDICT: ebbx___ , LABEL: ebbx___\n",
      "PREDICT: mw04___ , LABEL: mw04___\n",
      "PREDICT: zb_____ , LABEL: zb_____\n",
      "PREDICT: 3b_____ , LABEL: 3b_____\n",
      "PREDICT: 16b2xsj , LABEL: 16b2xsj\n",
      "PREDICT: jbu____ , LABEL: jbu____\n",
      "PREDICT: 5khma0_ , LABEL: 5khma0_\n",
      "PREDICT: 1x_____ , LABEL: 1x_____\n",
      "PREDICT: 7ap____ , LABEL: 7ap____\n",
      "PREDICT: jhij9v4 , LABEL: jhij9v4\n",
      "PREDICT: ywqvk6_ , LABEL: ywqvk6_\n",
      "PREDICT: kel3___ , LABEL: kel3___\n",
      "PREDICT: azcjtj_ , LABEL: azcjtj_\n",
      "PREDICT: 3jlafbg , LABEL: 3jlafbg\n",
      "PREDICT: fgh____ , LABEL: fgh____\n",
      "PREDICT: x10vkvw , LABEL: x10vkvw\n",
      "PREDICT: o4_____ , LABEL: o4_____\n",
      "PREDICT: vgqf7__ , LABEL: vgqf7__\n",
      "PREDICT: dun9k__ , LABEL: dun9k__\n",
      "PREDICT: x7kcr6s , LABEL: x7kcr6s\n",
      "PREDICT: kzll___ , LABEL: kzll___\n",
      "PREDICT: eyd5___ , LABEL: eyd5___\n",
      "PREDICT: qlis___ , LABEL: qlis___\n",
      "PREDICT: zbvwbod , LABEL: zbvwbod\n",
      "PREDICT: r8_____ , LABEL: r8_____\n",
      "PREDICT: 9rmoc6_ , LABEL: 9rmoc6_\n",
      "PREDICT: tqvlr9r , LABEL: tqvlr9r\n",
      "PREDICT: k3ws___ , LABEL: k3ws___\n",
      "PREDICT: 7ml7___ , LABEL: 7ml7___\n",
      "PREDICT: p3u____ , LABEL: p3u____\n",
      "PREDICT: vpqf___ , LABEL: vpqf___\n",
      "PREDICT: 78_____ , LABEL: 78_____\n",
      "PREDICT: 65_____ , LABEL: 65_____\n",
      "PREDICT: dycha__ , LABEL: dycha__\n",
      "PREDICT: z9hjo__ , LABEL: z9hjo__\n",
      "PREDICT: rza____ , LABEL: rza____\n",
      "PREDICT: 12_____ , LABEL: 12_____\n",
      "PREDICT: z2z216_ , LABEL: z2z216_\n",
      "PREDICT: 2c1l___ , LABEL: 2c1l___\n",
      "PREDICT: 9su8z__ , LABEL: 9su8z__\n",
      "PREDICT: dj4rf5t , LABEL: dj4rf5t\n",
      "PREDICT: rk4____ , LABEL: rk4____\n",
      "PREDICT: 98r0039 , LABEL: 98r0039\n",
      "PREDICT: 1bsu19_ , LABEL: 1bsu19_\n",
      "PREDICT: xnc3j__ , LABEL: xnc3j__\n",
      "PREDICT: xjgw___ , LABEL: xjgw___\n",
      "PREDICT: adzpmy_ , LABEL: adzpmy_\n",
      "PREDICT: 12dl0x0 , LABEL: 12dl0x0\n",
      "PREDICT: jolt___ , LABEL: jolt___\n",
      "PREDICT: aft____ , LABEL: aft____\n",
      "PREDICT: 49bx___ , LABEL: 49bx___\n",
      "PREDICT: 0l_____ , LABEL: 0l_____\n",
      "PREDICT: 34b5a__ , LABEL: 34b5a__\n",
      "PREDICT: em08oo_ , LABEL: em08oo_\n",
      "PREDICT: 69nv___ , LABEL: 69nv___\n",
      "PREDICT: wnael4_ , LABEL: wnael4_\n",
      "PREDICT: bjilou_ , LABEL: bjilou_\n",
      "PREDICT: kolq___ , LABEL: kolq___\n",
      "PREDICT: xg_____ , LABEL: xg_____\n",
      "PREDICT: 8k7x6ps , LABEL: 8k7x6ps\n",
      "PREDICT: bxpzzu_ , LABEL: bxpzzu_\n",
      "PREDICT: 5x2xak_ , LABEL: 5x2xak_\n",
      "PREDICT: b0ht___ , LABEL: b0ht___\n",
      "PREDICT: zgiry7b , LABEL: zgiry7b\n",
      "PREDICT: w5cm9__ , LABEL: w5cm9__\n",
      "PREDICT: dk6l___ , LABEL: dk6l___\n",
      "PREDICT: 3h_____ , LABEL: 3h_____\n",
      "PREDICT: hv2jyc_ , LABEL: hv2jyc_\n",
      "PREDICT: f2_____ , LABEL: f2_____\n",
      "PREDICT: vciari4 , LABEL: vciari4\n",
      "PREDICT: nqczb__ , LABEL: nqczb__\n",
      "PREDICT: kdaug__ , LABEL: kdaug__\n",
      "PREDICT: dy_____ , LABEL: dy_____\n",
      "PREDICT: kv0y___ , LABEL: kv0y___\n",
      "PREDICT: g00____ , LABEL: g00____\n",
      "PREDICT: vp0yvq0 , LABEL: vp0yvq0\n",
      "PREDICT: yl6wayi , LABEL: yl6wayi\n",
      "PREDICT: haze___ , LABEL: haze___\n",
      "PREDICT: moq1b__ , LABEL: moq1b__\n",
      "PREDICT: ojz____ , LABEL: ojz____\n",
      "PREDICT: hy7h___ , LABEL: hy7h___\n",
      "PREDICT: fyip___ , LABEL: fyip___\n",
      "PREDICT: kv7____ , LABEL: kv7____\n",
      "PREDICT: 78_____ , LABEL: 78_____\n",
      "PREDICT: k9t____ , LABEL: k9t____\n",
      "PREDICT: dtl9y3h , LABEL: dtl9y3h\n",
      "PREDICT: joyi4m6 , LABEL: joyi4m6\n",
      "PREDICT: ls6v___ , LABEL: ls6v___\n",
      "PREDICT: 5ktgws_ , LABEL: 5ktgws_\n",
      "PREDICT: j4i____ , LABEL: j4i____\n",
      "PREDICT: kk1og__ , LABEL: kk1og__\n",
      "PREDICT: r035ok_ , LABEL: r035ok_\n",
      "PREDICT: 1ec72px , LABEL: 1ec72px\n",
      "PREDICT: c7w____ , LABEL: c7w____\n",
      "PREDICT: x257u6_ , LABEL: x257u6_\n",
      "PREDICT: fy_____ , LABEL: fy_____\n",
      "PREDICT: gof8___ , LABEL: gof8___\n",
      "PREDICT: 2qvkvs_ , LABEL: 2qvkvs_\n",
      "PREDICT: uucx9__ , LABEL: uucx9__\n",
      "PREDICT: eu1fwf_ , LABEL: eu1fwf_\n",
      "PREDICT: e3_____ , LABEL: e3_____\n",
      "PREDICT: dak____ , LABEL: dak____\n",
      "PREDICT: eobg___ , LABEL: eobg___\n",
      "PREDICT: vs1____ , LABEL: vs1____\n",
      "PREDICT: yw_____ , LABEL: yw_____\n",
      "PREDICT: nq9g___ , LABEL: nq9g___\n",
      "PREDICT: j6e1pc_ , LABEL: j6e1pc_\n",
      "PREDICT: q02____ , LABEL: q02____\n",
      "PREDICT: to12___ , LABEL: to12___\n",
      "PREDICT: apd____ , LABEL: apd____\n",
      "PREDICT: swydk__ , LABEL: swydk__\n",
      "PREDICT: 7de7d__ , LABEL: 7de7d__\n",
      "PREDICT: v9s4cc5 , LABEL: v9s4cc5\n",
      "PREDICT: 3wc____ , LABEL: 3wc____\n",
      "PREDICT: 8j1____ , LABEL: 8j1____\n",
      "PREDICT: qwrhda2 , LABEL: qwrhda2\n",
      "PREDICT: lg4s___ , LABEL: lg4s___\n",
      "PREDICT: da1____ , LABEL: da1____\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: sj_____ , LABEL: sj_____\n",
      "PREDICT: 1suyf8_ , LABEL: 1suyf8_\n",
      "PREDICT: fblzo__ , LABEL: fblzo__\n",
      "PREDICT: gvlhn__ , LABEL: gvlhn__\n",
      "PREDICT: 0jj7w__ , LABEL: 0jj7w__\n",
      "PREDICT: e4o89r_ , LABEL: e4o89r_\n",
      "PREDICT: clwllf0 , LABEL: clwllf0\n",
      "PREDICT: nq_____ , LABEL: nq_____\n",
      "PREDICT: oljje__ , LABEL: oljje__\n",
      "PREDICT: wjrvnu_ , LABEL: wjrvnu_\n",
      "PREDICT: 6k8s94_ , LABEL: 6k8s94_\n",
      "PREDICT: pjd____ , LABEL: pjd____\n",
      "PREDICT: ekgvm__ , LABEL: ekgvm__\n",
      "PREDICT: bo4m0__ , LABEL: bo4m0__\n",
      "PREDICT: ultrlr_ , LABEL: ultrlr_\n",
      "PREDICT: t1_____ , LABEL: t1_____\n",
      "PREDICT: kq865m_ , LABEL: kq865m_\n",
      "PREDICT: 5zw8___ , LABEL: 5zw8___\n",
      "PREDICT: 3d_____ , LABEL: 3d_____\n",
      "PREDICT: blvaodq , LABEL: blvaodq\n",
      "PREDICT: 0myq___ , LABEL: 0myq___\n",
      "PREDICT: 4qdr___ , LABEL: 4qdr___\n",
      "PREDICT: ssj____ , LABEL: ssj____\n",
      "PREDICT: y7_____ , LABEL: y7_____\n",
      "PREDICT: 1lxjdnl , LABEL: 1lxjdnl\n",
      "PREDICT: szg____ , LABEL: szg____\n",
      "PREDICT: ac8____ , LABEL: ac8____\n",
      "PREDICT: 8qb____ , LABEL: 8qb____\n",
      "PREDICT: 5o_____ , LABEL: 5o_____\n",
      "PREDICT: lch0nrq , LABEL: lch0nrq\n",
      "PREDICT: vf6cuvl , LABEL: vf6cuvl\n",
      "PREDICT: ps_____ , LABEL: ps_____\n",
      "PREDICT: jwx51__ , LABEL: jwx51__\n",
      "PREDICT: x81t___ , LABEL: x81t___\n",
      "PREDICT: hhg90zg , LABEL: hhg90zg\n",
      "PREDICT: 4ygm___ , LABEL: 4ygm___\n",
      "PREDICT: qiog___ , LABEL: qiog___\n",
      "PREDICT: d0tox__ , LABEL: d0tox__\n",
      "PREDICT: ts30___ , LABEL: ts30___\n",
      "PREDICT: rlt3___ , LABEL: rlt3___\n",
      "PREDICT: 6bgn___ , LABEL: 6bgn___\n",
      "PREDICT: l9kmku_ , LABEL: l9kmku_\n",
      "PREDICT: 52_____ , LABEL: 52_____\n",
      "PREDICT: 54nq___ , LABEL: 54nq___\n",
      "PREDICT: 6b4____ , LABEL: 6b4____\n",
      "PREDICT: yljpagn , LABEL: yljpagn\n",
      "PREDICT: we_____ , LABEL: we_____\n",
      "PREDICT: yy32n__ , LABEL: yy32n__\n",
      "PREDICT: 1csdcpb , LABEL: 1csdcpb\n",
      "PREDICT: dovtu__ , LABEL: dovtu__\n",
      "PREDICT: w4jn6__ , LABEL: w4jn6__\n",
      "PREDICT: 26g1zi_ , LABEL: 26g1zi_\n",
      "PREDICT: ywwaj__ , LABEL: ywwaj__\n",
      "PREDICT: 2qhbr__ , LABEL: 2qhbr__\n",
      "PREDICT: 4iep5__ , LABEL: 4iep5__\n",
      "PREDICT: 228l4__ , LABEL: 228l4__\n",
      "PREDICT: yr1zarv , LABEL: yr1zarv\n",
      "PREDICT: fhf39lv , LABEL: fhf39lv\n",
      "PREDICT: wy_____ , LABEL: wy_____\n",
      "PREDICT: qpo____ , LABEL: qpo____\n",
      "PREDICT: tj54z__ , LABEL: tj54z__\n",
      "PREDICT: 6r_____ , LABEL: 6r_____\n",
      "PREDICT: plamwe_ , LABEL: plamwe_\n",
      "PREDICT: d80f894 , LABEL: d80f894\n",
      "PREDICT: boifyf0 , LABEL: boifyf0\n",
      "PREDICT: 90zkc__ , LABEL: 90zkc__\n",
      "PREDICT: yg4____ , LABEL: yg4____\n",
      "PREDICT: u0_____ , LABEL: u0_____\n",
      "PREDICT: nacz___ , LABEL: nacz___\n",
      "PREDICT: kveql__ , LABEL: kveql__\n",
      "PREDICT: euqj___ , LABEL: euqj___\n",
      "PREDICT: p71z___ , LABEL: p71z___\n",
      "PREDICT: pzfk19_ , LABEL: pzfk19_\n",
      "PREDICT: ler____ , LABEL: ler____\n",
      "PREDICT: lkxt___ , LABEL: lkxt___\n",
      "PREDICT: a1r____ , LABEL: a1r____\n",
      "PREDICT: 5akqu__ , LABEL: 5akqu__\n",
      "PREDICT: 2b_____ , LABEL: 2b_____\n",
      "PREDICT: 57_____ , LABEL: 57_____\n",
      "PREDICT: 0x77agf , LABEL: 0x77agf\n",
      "PREDICT: 2z_____ , LABEL: 2z_____\n",
      "PREDICT: eaufcp_ , LABEL: eaufcp_\n",
      "PREDICT: 95d7gh_ , LABEL: 95d7gh_\n",
      "PREDICT: zw_____ , LABEL: zw_____\n",
      "PREDICT: zhale__ , LABEL: zhale__\n",
      "PREDICT: zmbc1v_ , LABEL: zmbc1v_\n",
      "PREDICT: p5k52x5 , LABEL: p5k52x5\n",
      "PREDICT: oeguap7 , LABEL: oeguap7\n",
      "PREDICT: ju08___ , LABEL: ju08___\n",
      "PREDICT: lcodl32 , LABEL: lcodl32\n",
      "PREDICT: oz1qz__ , LABEL: oz1qz__\n",
      "PREDICT: 4r_____ , LABEL: 4r_____\n",
      "PREDICT: 3z_____ , LABEL: 3z_____\n",
      "PREDICT: b0s6dj_ , LABEL: b0s6dj_\n",
      "PREDICT: 5tn0___ , LABEL: 5tn0___\n",
      "PREDICT: nd_____ , LABEL: nd_____\n",
      "PREDICT: ujv____ , LABEL: ujv____\n",
      "PREDICT: ob_____ , LABEL: ob_____\n",
      "PREDICT: wbt5mv_ , LABEL: wbt5mv_\n",
      "PREDICT: 01flb__ , LABEL: 01flb__\n",
      "PREDICT: mtf____ , LABEL: mtf____\n",
      "PREDICT: 3vxt2__ , LABEL: 3vxt2__\n",
      "PREDICT: uv_____ , LABEL: uv_____\n",
      "PREDICT: sr_____ , LABEL: sr_____\n",
      "PREDICT: yc9h1i_ , LABEL: yc9h1i_\n",
      "PREDICT: s3h____ , LABEL: s3h____\n",
      "PREDICT: u9dgt6n , LABEL: u9dgt6n\n",
      "PREDICT: jocca__ , LABEL: jocca__\n",
      "PREDICT: w1f4___ , LABEL: w1f4___\n",
      "PREDICT: 7co____ , LABEL: 7co____\n",
      "PREDICT: f1_____ , LABEL: f1_____\n",
      "PREDICT: f74s___ , LABEL: f74s___\n",
      "PREDICT: 4v2o5u_ , LABEL: 4v2o5u_\n",
      "PREDICT: k31sgl4 , LABEL: k31sgl4\n",
      "PREDICT: c3o7___ , LABEL: c3o7___\n",
      "PREDICT: pf_____ , LABEL: pf_____\n",
      "PREDICT: 5j4m___ , LABEL: 5j4m___\n",
      "PREDICT: pf_____ , LABEL: pf_____\n",
      "PREDICT: i5hel3g , LABEL: i5hel3g\n",
      "PREDICT: wv_____ , LABEL: wv_____\n",
      "PREDICT: y0p29c_ , LABEL: y0p29c_\n",
      "PREDICT: s9al4__ , LABEL: s9al4__\n",
      "PREDICT: m21wx__ , LABEL: m21wx__\n",
      "PREDICT: 3roz___ , LABEL: 3roz___\n",
      "PREDICT: jx7qi__ , LABEL: jx7qi__\n",
      "PREDICT: 5gz____ , LABEL: 5gz____\n",
      "PREDICT: bi4____ , LABEL: bi4____\n",
      "PREDICT: aziua__ , LABEL: aziua__\n",
      "PREDICT: iin0bd_ , LABEL: iin0bd_\n",
      "PREDICT: ttmcovu , LABEL: ttmcovu\n",
      "PREDICT: k3n____ , LABEL: k3n____\n",
      "PREDICT: b7iy___ , LABEL: b7iy___\n",
      "PREDICT: i0g____ , LABEL: i0g____\n",
      "PREDICT: tx_____ , LABEL: tx_____\n",
      "PREDICT: 2ijjt22 , LABEL: 2ijjt22\n",
      "PREDICT: egy7lna , LABEL: egy7lna\n",
      "PREDICT: wmsarqo , LABEL: wmsarqo\n",
      "PREDICT: tir7w2u , LABEL: tir7w2u\n",
      "PREDICT: a8_____ , LABEL: a8_____\n",
      "PREDICT: flvhog9 , LABEL: flvhog9\n",
      "PREDICT: p5veu__ , LABEL: p5veu__\n",
      "PREDICT: 6r09gtb , LABEL: 6r09gtb\n",
      "PREDICT: yrswvm_ , LABEL: yrswvm_\n",
      "PREDICT: ao_____ , LABEL: ao_____\n",
      "PREDICT: tzu3iu_ , LABEL: tzu3iu_\n",
      "PREDICT: ha_____ , LABEL: ha_____\n",
      "PREDICT: l2i2x__ , LABEL: l2i2x__\n",
      "PREDICT: ru7l9l_ , LABEL: ru7l9l_\n",
      "PREDICT: wguz___ , LABEL: wguz___\n",
      "PREDICT: fgibx__ , LABEL: fgibx__\n",
      "PREDICT: nijfb__ , LABEL: nijfb__\n",
      "PREDICT: b5nqgd_ , LABEL: b5nqgd_\n",
      "PREDICT: 7h_____ , LABEL: 7h_____\n",
      "PREDICT: 0bt4r__ , LABEL: 0bt4r__\n",
      "PREDICT: zkf____ , LABEL: zkf____\n",
      "PREDICT: objck5z , LABEL: objck5z\n",
      "PREDICT: 3v2a___ , LABEL: 3v2a___\n",
      "PREDICT: 31c____ , LABEL: 31c____\n",
      "PREDICT: n0v____ , LABEL: n0v____\n",
      "PREDICT: 1sagap5 , LABEL: 1sagap5\n",
      "PREDICT: 75_____ , LABEL: 75_____\n",
      "PREDICT: oh71qk_ , LABEL: oh71qk_\n",
      "PREDICT: s3et___ , LABEL: s3et___\n",
      "PREDICT: 3pcxkf_ , LABEL: 3pcxkf_\n",
      "PREDICT: cult0__ , LABEL: cult0__\n",
      "PREDICT: futtqo_ , LABEL: futtqo_\n",
      "PREDICT: 4jiq___ , LABEL: 4jiq___\n",
      "PREDICT: bj_____ , LABEL: bj_____\n",
      "PREDICT: rsdqk__ , LABEL: rsdqk__\n",
      "PREDICT: 1a5____ , LABEL: 1a5____\n",
      "PREDICT: s28____ , LABEL: s28____\n",
      "PREDICT: rsd2___ , LABEL: rsd2___\n",
      "PREDICT: 28v8quh , LABEL: 28v8quh\n",
      "PREDICT: 1nckk9r , LABEL: 1nckk9r\n",
      "PREDICT: 7vlayvv , LABEL: 7vlayvv\n",
      "PREDICT: r2mk4__ , LABEL: r2mk4__\n",
      "PREDICT: 32_____ , LABEL: 32_____\n",
      "PREDICT: 00fc0p_ , LABEL: 00fc0p_\n",
      "PREDICT: gjwjtu2 , LABEL: gjwjtu2\n",
      "PREDICT: g0iqabl , LABEL: g0iqabl\n",
      "PREDICT: mw7va5n , LABEL: mw7va5n\n",
      "PREDICT: 6z2ppqr , LABEL: 6z2ppqr\n",
      "PREDICT: zz_____ , LABEL: zz_____\n",
      "PREDICT: wl1j___ , LABEL: wl1j___\n",
      "PREDICT: ngx1bfb , LABEL: ngx1bfb\n",
      "PREDICT: pmf4mp_ , LABEL: pmf4mp_\n",
      "PREDICT: cso60p_ , LABEL: cso60p_\n",
      "PREDICT: mu51j__ , LABEL: mu51j__\n",
      "PREDICT: 7m0d___ , LABEL: 7m0d___\n",
      "PREDICT: p1p46r_ , LABEL: p1p46r_\n",
      "PREDICT: jkl____ , LABEL: jkl____\n",
      "PREDICT: m4ep___ , LABEL: m4ep___\n",
      "PREDICT: 45gow__ , LABEL: 45gow__\n",
      "PREDICT: fm47___ , LABEL: fm47___\n",
      "PREDICT: n6a____ , LABEL: n6a____\n",
      "PREDICT: o3_____ , LABEL: o3_____\n",
      "PREDICT: alqv1__ , LABEL: alqv1__\n",
      "PREDICT: y79____ , LABEL: y79____\n",
      "PREDICT: h55z5a_ , LABEL: h55z5a_\n",
      "PREDICT: ujw____ , LABEL: ujw____\n",
      "PREDICT: grbw___ , LABEL: grbw___\n",
      "PREDICT: j56tqr_ , LABEL: j56tqr_\n",
      "PREDICT: ih6____ , LABEL: ih6____\n",
      "PREDICT: 6hz____ , LABEL: 6hz____\n",
      "PREDICT: 91kxnk0 , LABEL: 91kxnk0\n",
      "PREDICT: zzft___ , LABEL: zzft___\n",
      "PREDICT: 6m27rja , LABEL: 6m27rja\n",
      "PREDICT: mlzk___ , LABEL: mlzk___\n",
      "PREDICT: f1po1n9 , LABEL: f1po1n9\n",
      "PREDICT: 3ty____ , LABEL: 3ty____\n",
      "PREDICT: 8axgj6_ , LABEL: 8axgj6_\n",
      "PREDICT: bgntvuc , LABEL: bgntvuc\n",
      "PREDICT: bls____ , LABEL: bls____\n",
      "PREDICT: v38s___ , LABEL: v38s___\n",
      "PREDICT: s8udrn_ , LABEL: s8udrn_\n",
      "PREDICT: vyz5___ , LABEL: vyz5___\n",
      "PREDICT: jezewx4 , LABEL: jezewx4\n",
      "PREDICT: i115___ , LABEL: i115___\n",
      "PREDICT: zm5duc_ , LABEL: zm5duc_\n",
      "PREDICT: zeh____ , LABEL: zeh____\n",
      "PREDICT: 8e_____ , LABEL: 8e_____\n",
      "PREDICT: sxm____ , LABEL: sxm____\n",
      "PREDICT: lc7t___ , LABEL: lc7t___\n",
      "PREDICT: 486____ , LABEL: 486____\n",
      "PREDICT: zwwsk__ , LABEL: zwwsk__\n",
      "PREDICT: 3twtpuo , LABEL: 3twtpuo\n",
      "PREDICT: 70mswb9 , LABEL: 70mswb9\n",
      "PREDICT: 5q_____ , LABEL: 5q_____\n",
      "PREDICT: 9pq____ , LABEL: 9pq____\n",
      "PREDICT: s6b____ , LABEL: s6b____\n",
      "PREDICT: geat3w_ , LABEL: geat3w_\n",
      "PREDICT: jjt18z_ , LABEL: jjt18z_\n",
      "PREDICT: 6bocy2k , LABEL: 6bocy2k\n",
      "PREDICT: yxp39n4 , LABEL: yxp39n4\n",
      "PREDICT: ajpw___ , LABEL: ajpw___\n",
      "PREDICT: 2r_____ , LABEL: 2r_____\n",
      "PREDICT: 9mnf4a_ , LABEL: 9mnf4a_\n",
      "PREDICT: fyj6___ , LABEL: fyj6___\n",
      "PREDICT: 4o_____ , LABEL: 4o_____\n",
      "PREDICT: efbmb4o , LABEL: efbmb4o\n",
      "PREDICT: 9l_____ , LABEL: 9l_____\n",
      "PREDICT: elbx112 , LABEL: elbx112\n",
      "PREDICT: 0rl6abz , LABEL: 0rl6abz\n",
      "PREDICT: lx_____ , LABEL: lx_____\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: e9ab___ , LABEL: e9ab___\n",
      "PREDICT: lsr____ , LABEL: lsr____\n",
      "PREDICT: hvhj5__ , LABEL: hvhj5__\n",
      "PREDICT: d76____ , LABEL: d76____\n",
      "PREDICT: 502tru_ , LABEL: 502tru_\n",
      "PREDICT: 33mykb_ , LABEL: 33mykb_\n",
      "PREDICT: 8fbh___ , LABEL: 8fbh___\n",
      "PREDICT: 2ase___ , LABEL: 2ase___\n",
      "PREDICT: axi1m__ , LABEL: axi1m__\n",
      "PREDICT: 43_____ , LABEL: 43_____\n",
      "PREDICT: 7jy____ , LABEL: 7jy____\n",
      "PREDICT: j9yl___ , LABEL: j9yl___\n",
      "PREDICT: fu_____ , LABEL: fu_____\n",
      "PREDICT: yv2____ , LABEL: yv2____\n",
      "PREDICT: 27f____ , LABEL: 27f____\n",
      "PREDICT: i1u____ , LABEL: i1u____\n",
      "PREDICT: j0ty___ , LABEL: j0ty___\n",
      "PREDICT: qba4tor , LABEL: qba4tor\n",
      "PREDICT: cai____ , LABEL: cai____\n",
      "PREDICT: vf_____ , LABEL: vf_____\n",
      "PREDICT: sdy____ , LABEL: sdy____\n",
      "PREDICT: 1wk2pi_ , LABEL: 1wk2pi_\n",
      "PREDICT: 7v_____ , LABEL: 7v_____\n",
      "PREDICT: 8rvuoi_ , LABEL: 8rvuoi_\n",
      "PREDICT: aa_____ , LABEL: aa_____\n",
      "PREDICT: 79cnkb_ , LABEL: 79cnkb_\n",
      "PREDICT: 981o0cz , LABEL: 981o0cz\n",
      "PREDICT: 2k_____ , LABEL: 2k_____\n",
      "PREDICT: 98_____ , LABEL: 98_____\n",
      "PREDICT: tg_____ , LABEL: tg_____\n",
      "PREDICT: 5q8ez__ , LABEL: 5q8ez__\n",
      "PREDICT: dxc____ , LABEL: dxc____\n",
      "PREDICT: 4ijpc5_ , LABEL: 4ijpc5_\n",
      "PREDICT: aoklrle , LABEL: aoklrle\n",
      "PREDICT: mykdo__ , LABEL: mykdo__\n",
      "PREDICT: p8e____ , LABEL: p8e____\n",
      "PREDICT: 969i___ , LABEL: 969i___\n",
      "PREDICT: f2p5___ , LABEL: f2p5___\n",
      "PREDICT: yac____ , LABEL: yac____\n",
      "PREDICT: hg14sy_ , LABEL: hg14sy_\n",
      "PREDICT: rp_____ , LABEL: rp_____\n",
      "PREDICT: zno____ , LABEL: zno____\n",
      "PREDICT: ke2____ , LABEL: ke2____\n",
      "PREDICT: 0y07y__ , LABEL: 0y07y__\n",
      "PREDICT: 3h_____ , LABEL: 3h_____\n",
      "PREDICT: p2_____ , LABEL: p2_____\n",
      "PREDICT: 2jnv___ , LABEL: 2jnv___\n",
      "PREDICT: ty1e74_ , LABEL: ty1e74_\n",
      "PREDICT: 90zx6qs , LABEL: 90zx6qs\n",
      "PREDICT: 80c____ , LABEL: 80c____\n",
      "PREDICT: lcw____ , LABEL: lcw____\n",
      "PREDICT: fhbqe__ , LABEL: fhbqe__\n",
      "PREDICT: ku_____ , LABEL: ku_____\n",
      "PREDICT: kyz____ , LABEL: kyz____\n",
      "PREDICT: 3qewkt_ , LABEL: 3qewkt_\n",
      "PREDICT: mld687_ , LABEL: mld687_\n",
      "PREDICT: u8_____ , LABEL: u8_____\n",
      "PREDICT: s5_____ , LABEL: s5_____\n",
      "PREDICT: db3____ , LABEL: db3____\n",
      "PREDICT: h3peof_ , LABEL: h3peof_\n",
      "PREDICT: qt5____ , LABEL: qt5____\n",
      "PREDICT: swv3r__ , LABEL: swv3r__\n",
      "PREDICT: kpcxpxp , LABEL: kpcxpxp\n",
      "PREDICT: 2tryl__ , LABEL: 2tryl__\n",
      "PREDICT: y9a____ , LABEL: y9a____\n",
      "PREDICT: f5z324_ , LABEL: f5z324_\n",
      "PREDICT: 5hp____ , LABEL: 5hp____\n",
      "PREDICT: 559____ , LABEL: 559____\n",
      "PREDICT: osnob7_ , LABEL: osnob7_\n",
      "PREDICT: vmzfb__ , LABEL: vmzfb__\n",
      "PREDICT: xbi____ , LABEL: xbi____\n",
      "PREDICT: 2ntmp__ , LABEL: 2ntmp__\n",
      "PREDICT: 47_____ , LABEL: 47_____\n",
      "PREDICT: vd5dptt , LABEL: vd5dptt\n",
      "PREDICT: en_____ , LABEL: en_____\n",
      "PREDICT: itol5__ , LABEL: itol5__\n",
      "PREDICT: csomds_ , LABEL: csomds_\n",
      "PREDICT: jmycb8_ , LABEL: jmycb8_\n",
      "PREDICT: mkzcr__ , LABEL: mkzcr__\n",
      "PREDICT: 5556___ , LABEL: 5556___\n",
      "PREDICT: lqzx___ , LABEL: lqzx___\n",
      "PREDICT: xb3czxg , LABEL: xb3czxg\n",
      "PREDICT: cuxo3x_ , LABEL: cuxo3x_\n",
      "PREDICT: cok____ , LABEL: cok____\n",
      "PREDICT: ucv5___ , LABEL: ucv5___\n",
      "PREDICT: td5esx_ , LABEL: td5esx_\n",
      "PREDICT: o6oeh__ , LABEL: o6oeh__\n",
      "PREDICT: a474___ , LABEL: a474___\n",
      "PREDICT: olnm___ , LABEL: olnm___\n",
      "PREDICT: vtj7nq0 , LABEL: vtj7nq0\n",
      "PREDICT: p3t____ , LABEL: p3t____\n",
      "PREDICT: 43_____ , LABEL: 43_____\n",
      "PREDICT: a95iya_ , LABEL: a95iya_\n",
      "PREDICT: qmesx4p , LABEL: qmesx4p\n",
      "PREDICT: tbsihj5 , LABEL: tbsihj5\n",
      "PREDICT: ia_____ , LABEL: ia_____\n",
      "PREDICT: ku7v___ , LABEL: ku7v___\n",
      "PREDICT: 7mgp___ , LABEL: 7mgp___\n",
      "PREDICT: 71_____ , LABEL: 71_____\n",
      "PREDICT: sk_____ , LABEL: sk_____\n",
      "PREDICT: 0ucfoe_ , LABEL: 0ucfoe_\n",
      "PREDICT: 08tms__ , LABEL: 08tms__\n",
      "PREDICT: w3pi___ , LABEL: w3pi___\n",
      "PREDICT: l6y____ , LABEL: l6y____\n",
      "PREDICT: mjalz8h , LABEL: mjalz8h\n",
      "PREDICT: m3h____ , LABEL: m3h____\n",
      "PREDICT: upw43__ , LABEL: upw43__\n",
      "PREDICT: dk6k5h_ , LABEL: dk6k5h_\n",
      "PREDICT: 5n5____ , LABEL: 5n5____\n",
      "PREDICT: gpfj___ , LABEL: gpfj___\n",
      "PREDICT: 21s0tq_ , LABEL: 21s0tq_\n",
      "PREDICT: f8p9myt , LABEL: f8p9myt\n",
      "PREDICT: am_____ , LABEL: am_____\n",
      "PREDICT: mwu6___ , LABEL: mwu6___\n",
      "PREDICT: f130c__ , LABEL: f130c__\n",
      "PREDICT: g78r9h_ , LABEL: g78r9h_\n",
      "PREDICT: ujc1f__ , LABEL: ujc1f__\n",
      "PREDICT: 7c2____ , LABEL: 7c2____\n",
      "PREDICT: 3kb13i_ , LABEL: 3kb13i_\n",
      "PREDICT: m609t13 , LABEL: m609t13\n",
      "PREDICT: 6b9c___ , LABEL: 6b9c___\n",
      "PREDICT: tuesk__ , LABEL: tuesk__\n",
      "PREDICT: kuiwx__ , LABEL: kuiwx__\n",
      "PREDICT: hug7aq_ , LABEL: hug7aq_\n",
      "PREDICT: l2dy7x_ , LABEL: l2dy7x_\n",
      "PREDICT: 20x____ , LABEL: 20x____\n",
      "PREDICT: n3g3jnp , LABEL: n3g3jnp\n",
      "PREDICT: asg2___ , LABEL: asg2___\n",
      "PREDICT: g4_____ , LABEL: g4_____\n",
      "PREDICT: fsjfg__ , LABEL: fsjfg__\n",
      "PREDICT: 411____ , LABEL: 411____\n",
      "PREDICT: dabh59_ , LABEL: dabh59_\n",
      "PREDICT: 5dpel__ , LABEL: 5dpel__\n",
      "PREDICT: 1gtt2hk , LABEL: 1gtt2hk\n",
      "PREDICT: vi_____ , LABEL: vi_____\n",
      "PREDICT: mpyxi__ , LABEL: mpyxi__\n",
      "PREDICT: e0vm___ , LABEL: e0vm___\n",
      "PREDICT: geretoh , LABEL: geretoh\n",
      "PREDICT: 7x_____ , LABEL: 7x_____\n",
      "PREDICT: zd9k___ , LABEL: zd9k___\n",
      "PREDICT: bm_____ , LABEL: bm_____\n",
      "PREDICT: cim____ , LABEL: cim____\n",
      "PREDICT: 41pp___ , LABEL: 41pp___\n",
      "PREDICT: ruwz2y_ , LABEL: ruwz2y_\n",
      "PREDICT: p8_____ , LABEL: p8_____\n",
      "PREDICT: kbf7___ , LABEL: kbf7___\n",
      "PREDICT: hdkyip6 , LABEL: hdkyip6\n",
      "PREDICT: 39c____ , LABEL: 39c____\n",
      "PREDICT: n17yop_ , LABEL: n17yop_\n",
      "PREDICT: 2o_____ , LABEL: 2o_____\n",
      "PREDICT: pkklb6_ , LABEL: pkklb6_\n",
      "PREDICT: 8klf___ , LABEL: 8klf___\n",
      "PREDICT: tr_____ , LABEL: tr_____\n",
      "PREDICT: 3q7____ , LABEL: 3q7____\n",
      "PREDICT: 4hbb___ , LABEL: 4hbb___\n",
      "PREDICT: 3wqq5__ , LABEL: 3wqq5__\n",
      "PREDICT: 03w6fv_ , LABEL: 03w6fv_\n",
      "PREDICT: cqr____ , LABEL: cqr____\n",
      "PREDICT: vdu32__ , LABEL: vdu32__\n",
      "PREDICT: mx_____ , LABEL: mx_____\n",
      "PREDICT: 0wu____ , LABEL: 0wu____\n",
      "PREDICT: gr_____ , LABEL: gr_____\n",
      "PREDICT: db2a___ , LABEL: db2a___\n",
      "PREDICT: yxpl0b3 , LABEL: yxpl0b3\n",
      "PREDICT: hn1n___ , LABEL: hn1n___\n",
      "PREDICT: stko___ , LABEL: stko___\n",
      "PREDICT: 6tbe9fx , LABEL: 6tbe9fx\n",
      "PREDICT: diz8j__ , LABEL: diz8j__\n",
      "PREDICT: 26l6p__ , LABEL: 26l6p__\n",
      "PREDICT: rcam___ , LABEL: rcam___\n",
      "PREDICT: ul8____ , LABEL: ul8____\n",
      "PREDICT: znv0rn_ , LABEL: znv0rn_\n",
      "PREDICT: 1fu48y0 , LABEL: 1fu48y0\n",
      "PREDICT: d8s____ , LABEL: d8s____\n",
      "PREDICT: qot____ , LABEL: qot____\n",
      "PREDICT: 9y4x___ , LABEL: 9y4x___\n",
      "PREDICT: mqbnmd_ , LABEL: mqbnmd_\n",
      "PREDICT: cjl79__ , LABEL: cjl79__\n",
      "PREDICT: ha1s9__ , LABEL: ha1s9__\n",
      "PREDICT: 8w_____ , LABEL: 8w_____\n",
      "PREDICT: biv6s__ , LABEL: biv6s__\n",
      "PREDICT: 5imz2gq , LABEL: 5imz2gq\n",
      "PREDICT: rb1j___ , LABEL: rb1j___\n",
      "PREDICT: pxjq___ , LABEL: pxjq___\n",
      "PREDICT: ze2wfc_ , LABEL: ze2wfc_\n",
      "PREDICT: 201____ , LABEL: 201____\n",
      "PREDICT: ju_____ , LABEL: ju_____\n",
      "PREDICT: pdg7rk_ , LABEL: pdg7rk_\n",
      "PREDICT: hvoy___ , LABEL: hvoy___\n",
      "PREDICT: 0h0qwr8 , LABEL: 0h0qwr8\n",
      "PREDICT: qsotw7_ , LABEL: qsotw7_\n",
      "PREDICT: gs4e___ , LABEL: gs4e___\n",
      "PREDICT: k8gz___ , LABEL: k8gz___\n",
      "PREDICT: y7ax___ , LABEL: y7ax___\n",
      "PREDICT: 9ubz1__ , LABEL: 9ubz1__\n",
      "PREDICT: uqx____ , LABEL: uqx____\n",
      "PREDICT: pp_____ , LABEL: pp_____\n",
      "PREDICT: yra3___ , LABEL: yra3___\n",
      "PREDICT: sc_____ , LABEL: sc_____\n",
      "PREDICT: 7blu3__ , LABEL: 7blu3__\n",
      "PREDICT: g59____ , LABEL: g59____\n",
      "PREDICT: m9ed6k_ , LABEL: m9ed6k_\n",
      "PREDICT: ckt____ , LABEL: ckt____\n",
      "PREDICT: 712____ , LABEL: 712____\n",
      "PREDICT: y8nleg_ , LABEL: y8nleg_\n",
      "PREDICT: bxs5___ , LABEL: bxs5___\n",
      "PREDICT: 5f28y__ , LABEL: 5f28y__\n",
      "PREDICT: ga_____ , LABEL: ga_____\n",
      "PREDICT: k9w____ , LABEL: k9w____\n",
      "PREDICT: m4o2z__ , LABEL: m4o2z__\n",
      "PREDICT: pgr____ , LABEL: pgr____\n",
      "PREDICT: 9uft7en , LABEL: 9uft7en\n",
      "PREDICT: jpf758_ , LABEL: jpf758_\n",
      "PREDICT: 7ri46wm , LABEL: 7ri46wm\n",
      "PREDICT: ixpw9s_ , LABEL: ixpw9s_\n",
      "PREDICT: 7m8b3h_ , LABEL: 7m8b3h_\n",
      "PREDICT: nhi____ , LABEL: nhi____\n",
      "PREDICT: t8_____ , LABEL: t8_____\n",
      "PREDICT: wejqswc , LABEL: wejqswc\n",
      "PREDICT: h6a1___ , LABEL: h6a1___\n",
      "PREDICT: xutngu7 , LABEL: xutngu7\n",
      "PREDICT: drohaq_ , LABEL: drohaq_\n",
      "PREDICT: t2e8l5s , LABEL: t2e8l5s\n",
      "PREDICT: piiw___ , LABEL: piiw___\n",
      "PREDICT: i5gl6__ , LABEL: i5gl6__\n",
      "PREDICT: 744____ , LABEL: 744____\n",
      "PREDICT: t8phmqr , LABEL: t8phmqr\n",
      "PREDICT: vslyi__ , LABEL: vslyi__\n",
      "PREDICT: vcsm___ , LABEL: vcsm___\n",
      "PREDICT: 7nw7yvh , LABEL: 7nw7yvh\n",
      "PREDICT: gqykaa4 , LABEL: gqykaa4\n",
      "PREDICT: pts____ , LABEL: pts____\n",
      "PREDICT: 9l8____ , LABEL: 9l8____\n",
      "PREDICT: fwu4e__ , LABEL: fwu4e__\n",
      "PREDICT: 5n3y8r_ , LABEL: 5n3y8r_\n",
      "PREDICT: 7klxsz_ , LABEL: 7klxsz_\n",
      "PREDICT: 2vn____ , LABEL: 2vn____\n",
      "PREDICT: nzh____ , LABEL: nzh____\n",
      "PREDICT: 69gfvp_ , LABEL: 69gfvp_\n",
      "PREDICT: 1afuo__ , LABEL: 1afuo__\n",
      "PREDICT: uixo___ , LABEL: uixo___\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: jlh____ , LABEL: jlh____\n",
      "PREDICT: rbam3rb , LABEL: rbam3rb\n",
      "PREDICT: v8_____ , LABEL: v8_____\n",
      "PREDICT: u75mm__ , LABEL: u75mm__\n",
      "PREDICT: x6thn4h , LABEL: x6thn4h\n",
      "PREDICT: 6c8n___ , LABEL: 6c8n___\n",
      "PREDICT: vohcc__ , LABEL: vohcc__\n",
      "PREDICT: 0f3ad__ , LABEL: 0f3ad__\n",
      "PREDICT: a8wmu__ , LABEL: a8wmu__\n",
      "PREDICT: 1dd4___ , LABEL: 1dd4___\n",
      "PREDICT: e0hx___ , LABEL: e0hx___\n",
      "PREDICT: af7g___ , LABEL: af7g___\n",
      "PREDICT: x3nr9__ , LABEL: x3nr9__\n",
      "PREDICT: wd_____ , LABEL: wd_____\n",
      "PREDICT: a2_____ , LABEL: a2_____\n",
      "PREDICT: vd_____ , LABEL: vd_____\n",
      "PREDICT: wu7hqy_ , LABEL: wu7hqy_\n",
      "PREDICT: bv3k___ , LABEL: bv3k___\n",
      "PREDICT: 1k5____ , LABEL: 1k5____\n",
      "PREDICT: acq____ , LABEL: acq____\n",
      "PREDICT: 4f_____ , LABEL: 4f_____\n",
      "PREDICT: 4pu5t__ , LABEL: 4pu5t__\n",
      "PREDICT: fsbfk5z , LABEL: fsbfk5z\n",
      "PREDICT: zv_____ , LABEL: zv_____\n",
      "PREDICT: 08p____ , LABEL: 08p____\n",
      "PREDICT: svixy__ , LABEL: svixy__\n",
      "PREDICT: qjidg__ , LABEL: qjidg__\n",
      "PREDICT: fn_____ , LABEL: fn_____\n",
      "PREDICT: p4tvr__ , LABEL: p4tvr__\n",
      "PREDICT: pl2____ , LABEL: pl2____\n",
      "PREDICT: 5q5rs__ , LABEL: 5q5rs__\n",
      "PREDICT: fe0vt3z , LABEL: fe0vt3z\n",
      "PREDICT: go9____ , LABEL: go9____\n",
      "PREDICT: b0dlqd_ , LABEL: b0dlqd_\n",
      "PREDICT: cprqk2_ , LABEL: cprqk2_\n",
      "PREDICT: 0l4____ , LABEL: 0l4____\n",
      "PREDICT: nwh____ , LABEL: nwh____\n",
      "PREDICT: lcvkn__ , LABEL: lcvkn__\n",
      "PREDICT: uoe4fg_ , LABEL: uoe4fg_\n",
      "PREDICT: mrpy___ , LABEL: mrpy___\n",
      "PREDICT: oigt5__ , LABEL: oigt5__\n",
      "PREDICT: lag6v__ , LABEL: lag6v__\n",
      "PREDICT: uwz1___ , LABEL: uwz1___\n",
      "PREDICT: 0e_____ , LABEL: 0e_____\n",
      "PREDICT: nzc____ , LABEL: nzc____\n",
      "PREDICT: pyrk64_ , LABEL: pyrk64_\n",
      "PREDICT: niomt__ , LABEL: niomt__\n",
      "PREDICT: k82tn5_ , LABEL: k82tn5_\n",
      "PREDICT: cxnp___ , LABEL: cxnp___\n",
      "PREDICT: taa____ , LABEL: taa____\n",
      "PREDICT: l1y30b_ , LABEL: l1y30b_\n",
      "PREDICT: 133____ , LABEL: 133____\n",
      "PREDICT: q43p___ , LABEL: q43p___\n",
      "PREDICT: c39lf4_ , LABEL: c39lf4_\n",
      "PREDICT: g4bb8tw , LABEL: g4bb8tw\n",
      "PREDICT: wxu____ , LABEL: wxu____\n",
      "PREDICT: 62_____ , LABEL: 62_____\n",
      "PREDICT: akgt___ , LABEL: akgt___\n",
      "PREDICT: 3bwnxy_ , LABEL: 3bwnxy_\n",
      "PREDICT: pbm____ , LABEL: pbm____\n",
      "PREDICT: psh8___ , LABEL: psh8___\n",
      "PREDICT: j64l0t3 , LABEL: j64l0t3\n",
      "PREDICT: 4b3ftl_ , LABEL: 4b3ftl_\n",
      "PREDICT: b8_____ , LABEL: b8_____\n",
      "PREDICT: 0da9hs2 , LABEL: 0da9hs2\n",
      "PREDICT: w6_____ , LABEL: w6_____\n",
      "PREDICT: wj_____ , LABEL: wj_____\n",
      "PREDICT: k4e____ , LABEL: k4e____\n",
      "PREDICT: uzyt3__ , LABEL: uzyt3__\n",
      "PREDICT: wqmi1tl , LABEL: wqmi1tl\n",
      "PREDICT: mwlqu34 , LABEL: mwlqu34\n",
      "PREDICT: rr_____ , LABEL: rr_____\n",
      "PREDICT: e4ysfw_ , LABEL: e4ysfw_\n",
      "PREDICT: if_____ , LABEL: if_____\n",
      "PREDICT: ft03nl7 , LABEL: ft03nl7\n",
      "PREDICT: zfmcg__ , LABEL: zfmcg__\n",
      "PREDICT: ak2t___ , LABEL: ak2t___\n",
      "PREDICT: cpt5y__ , LABEL: cpt5y__\n",
      "PREDICT: e6fuuwg , LABEL: e6fuuwg\n",
      "PREDICT: wv9lpcm , LABEL: wv9lpcm\n",
      "PREDICT: dt2____ , LABEL: dt2____\n",
      "PREDICT: bjg____ , LABEL: bjg____\n",
      "PREDICT: nadfo__ , LABEL: nadfo__\n",
      "PREDICT: nn1____ , LABEL: nn1____\n",
      "PREDICT: d5wyr__ , LABEL: d5wyr__\n",
      "PREDICT: qltxg__ , LABEL: qltxg__\n",
      "PREDICT: 0ui28ae , LABEL: 0ui28ae\n",
      "PREDICT: bcbfzt3 , LABEL: bcbfzt3\n",
      "PREDICT: hxg7___ , LABEL: hxg7___\n",
      "PREDICT: 3icmegr , LABEL: 3icmegr\n",
      "PREDICT: i2css__ , LABEL: i2css__\n",
      "PREDICT: 40c2h9_ , LABEL: 40c2h9_\n",
      "PREDICT: 9y_____ , LABEL: 9y_____\n",
      "PREDICT: uwfs2y_ , LABEL: uwfs2y_\n",
      "PREDICT: j9fg9__ , LABEL: j9fg9__\n",
      "PREDICT: wmde___ , LABEL: wmde___\n",
      "PREDICT: q3sm___ , LABEL: q3sm___\n",
      "PREDICT: cr1g___ , LABEL: cr1g___\n",
      "PREDICT: nlc____ , LABEL: nlc____\n",
      "PREDICT: x0_____ , LABEL: x0_____\n",
      "PREDICT: 53c____ , LABEL: 53c____\n",
      "PREDICT: fjcl___ , LABEL: fjcl___\n",
      "PREDICT: nmb5___ , LABEL: nmb5___\n",
      "PREDICT: gh_____ , LABEL: gh_____\n",
      "PREDICT: 2km____ , LABEL: 2km____\n",
      "PREDICT: rhd____ , LABEL: rhd____\n",
      "PREDICT: cyeznl_ , LABEL: cyeznl_\n",
      "PREDICT: mrmap__ , LABEL: mrmap__\n",
      "PREDICT: rtr____ , LABEL: rtr____\n",
      "PREDICT: o4ezy__ , LABEL: o4ezy__\n",
      "PREDICT: c4vi___ , LABEL: c4vi___\n",
      "PREDICT: r1bj6ij , LABEL: r1bj6ij\n",
      "PREDICT: mh_____ , LABEL: mh_____\n",
      "PREDICT: lxdp9__ , LABEL: lxdp9__\n",
      "PREDICT: 8l_____ , LABEL: 8l_____\n",
      "PREDICT: qy_____ , LABEL: qy_____\n",
      "PREDICT: 2lk5___ , LABEL: 2lk5___\n",
      "PREDICT: kx8ku8z , LABEL: kx8ku8z\n",
      "PREDICT: v6af___ , LABEL: v6af___\n",
      "PREDICT: jy_____ , LABEL: jy_____\n",
      "PREDICT: gxfd___ , LABEL: gxfd___\n",
      "PREDICT: 6gov3hf , LABEL: 6gov3hf\n",
      "PREDICT: ue_____ , LABEL: ue_____\n",
      "PREDICT: fm5____ , LABEL: fm5____\n",
      "PREDICT: v1_____ , LABEL: v1_____\n",
      "PREDICT: oj_____ , LABEL: oj_____\n",
      "PREDICT: 71q5xiq , LABEL: 71q5xiq\n",
      "PREDICT: 3oi5___ , LABEL: 3oi5___\n",
      "PREDICT: yp4____ , LABEL: yp4____\n",
      "PREDICT: 5l7dc__ , LABEL: 5l7dc__\n",
      "PREDICT: b8a____ , LABEL: b8a____\n",
      "PREDICT: dcml___ , LABEL: dcml___\n",
      "PREDICT: sjzta1d , LABEL: sjzta1d\n",
      "PREDICT: 0iu____ , LABEL: 0iu____\n",
      "PREDICT: gjd____ , LABEL: gjd____\n",
      "PREDICT: d04____ , LABEL: d04____\n",
      "PREDICT: 7cc7rwo , LABEL: 7cc7rwo\n",
      "PREDICT: rsc5___ , LABEL: rsc5___\n",
      "PREDICT: cjzd___ , LABEL: cjzd___\n",
      "PREDICT: kmaqe2_ , LABEL: kmaqe2_\n",
      "PREDICT: p94m___ , LABEL: p94m___\n",
      "PREDICT: 8sf38__ , LABEL: 8sf38__\n",
      "PREDICT: ojt3l1_ , LABEL: ojt3l1_\n",
      "PREDICT: sl_____ , LABEL: sl_____\n",
      "PREDICT: dy_____ , LABEL: dy_____\n",
      "PREDICT: 1zo1___ , LABEL: 1zo1___\n",
      "PREDICT: jsftxe0 , LABEL: jsftxe0\n",
      "PREDICT: bh0i7__ , LABEL: bh0i7__\n",
      "PREDICT: gth5___ , LABEL: gth5___\n",
      "PREDICT: o2x____ , LABEL: o2x____\n",
      "PREDICT: km_____ , LABEL: km_____\n",
      "PREDICT: gmhtuua , LABEL: gmhtuua\n",
      "PREDICT: bc8wmaq , LABEL: bc8wmaq\n",
      "PREDICT: ng_____ , LABEL: ng_____\n",
      "PREDICT: cen____ , LABEL: cen____\n",
      "PREDICT: azoo___ , LABEL: azoo___\n",
      "PREDICT: djhno__ , LABEL: djhno__\n",
      "PREDICT: 383eb7f , LABEL: 383eb7f\n",
      "PREDICT: lc_____ , LABEL: lc_____\n",
      "PREDICT: cpr5___ , LABEL: cpr5___\n",
      "PREDICT: b5y____ , LABEL: b5y____\n",
      "PREDICT: 5ksmc6_ , LABEL: 5ksmc6_\n",
      "PREDICT: w3i3d02 , LABEL: w3i3d02\n",
      "PREDICT: ape____ , LABEL: ape____\n",
      "PREDICT: 6n5____ , LABEL: 6n5____\n",
      "PREDICT: v5kjn__ , LABEL: v5kjn__\n",
      "PREDICT: 7m5tt__ , LABEL: 7m5tt__\n",
      "PREDICT: i7iy88t , LABEL: i7iy88t\n",
      "PREDICT: chkliel , LABEL: chkliel\n",
      "PREDICT: 74se0xb , LABEL: 74se0xb\n",
      "PREDICT: 2nltur_ , LABEL: 2nltur_\n",
      "PREDICT: atwxzxh , LABEL: atwxzxh\n",
      "PREDICT: row____ , LABEL: row____\n",
      "PREDICT: z6z9e__ , LABEL: z6z9e__\n",
      "PREDICT: todgz2_ , LABEL: todgz2_\n",
      "PREDICT: 55erlmz , LABEL: 55erlmz\n",
      "PREDICT: wj8____ , LABEL: wj8____\n",
      "PREDICT: 7ou2ozo , LABEL: 7ou2ozo\n",
      "PREDICT: p0m6t5_ , LABEL: p0m6t5_\n",
      "PREDICT: 809p18m , LABEL: 809p18m\n",
      "PREDICT: 3eju___ , LABEL: 3eju___\n",
      "PREDICT: 4742vnv , LABEL: 4742vnv\n",
      "PREDICT: 1bolii_ , LABEL: 1bolii_\n",
      "PREDICT: wdwvi__ , LABEL: wdwvi__\n",
      "PREDICT: v8w8qt2 , LABEL: v8w8qt2\n",
      "PREDICT: yy_____ , LABEL: yy_____\n",
      "PREDICT: xzslx1y , LABEL: xzslx1y\n",
      "PREDICT: kv9ydw_ , LABEL: kv9ydw_\n",
      "PREDICT: 1og____ , LABEL: 1og____\n",
      "PREDICT: eijcag_ , LABEL: eijcag_\n",
      "PREDICT: ctf6___ , LABEL: ctf6___\n",
      "PREDICT: a4fa7kz , LABEL: a4fa7kz\n",
      "PREDICT: s1ns8e_ , LABEL: s1ns8e_\n",
      "PREDICT: cqi57jg , LABEL: cqi57jg\n",
      "PREDICT: d4oxgfk , LABEL: d4oxgfk\n",
      "PREDICT: u8qba8_ , LABEL: u8qba8_\n",
      "PREDICT: uqqay__ , LABEL: uqqay__\n",
      "PREDICT: x8vg___ , LABEL: x8vg___\n",
      "PREDICT: 5c20___ , LABEL: 5c20___\n",
      "PREDICT: 65629x9 , LABEL: 65629x9\n",
      "PREDICT: l1jo___ , LABEL: l1jo___\n",
      "PREDICT: 3v_____ , LABEL: 3v_____\n",
      "PREDICT: qj_____ , LABEL: qj_____\n",
      "PREDICT: zjq____ , LABEL: zjq____\n",
      "PREDICT: 57_____ , LABEL: 57_____\n",
      "PREDICT: mgo5whh , LABEL: mgo5whh\n",
      "PREDICT: glgp___ , LABEL: glgp___\n",
      "PREDICT: wqr____ , LABEL: wqr____\n",
      "PREDICT: maj0md_ , LABEL: maj0md_\n",
      "PREDICT: 88z____ , LABEL: 88z____\n",
      "PREDICT: 3k5____ , LABEL: 3k5____\n",
      "PREDICT: jg83___ , LABEL: jg83___\n",
      "PREDICT: 56zqvwy , LABEL: 56zqvwy\n",
      "PREDICT: jq9yf__ , LABEL: jq9yf__\n",
      "PREDICT: n29d___ , LABEL: n29d___\n",
      "PREDICT: 14syw__ , LABEL: 14syw__\n",
      "PREDICT: 2kh6___ , LABEL: 2kh6___\n",
      "PREDICT: 1tq1___ , LABEL: 1tq1___\n",
      "PREDICT: 86kinm_ , LABEL: 86kinm_\n",
      "PREDICT: 6z3____ , LABEL: 6z3____\n",
      "PREDICT: 43_____ , LABEL: 43_____\n",
      "PREDICT: 26ck1fh , LABEL: 26ck1fh\n",
      "PREDICT: akf8___ , LABEL: akf8___\n",
      "PREDICT: mlz____ , LABEL: mlz____\n",
      "PREDICT: 8qv____ , LABEL: 8qv____\n",
      "PREDICT: 8m89e__ , LABEL: 8m89e__\n",
      "PREDICT: r9wra__ , LABEL: r9wra__\n",
      "PREDICT: xc9qrt_ , LABEL: xc9qrt_\n",
      "PREDICT: w38____ , LABEL: w38____\n",
      "PREDICT: slw5pq_ , LABEL: slw5pq_\n",
      "PREDICT: aa5qoi0 , LABEL: aa5qoi0\n",
      "PREDICT: 0x7____ , LABEL: 0x7____\n",
      "PREDICT: 3w_____ , LABEL: 3w_____\n",
      "PREDICT: faft2b_ , LABEL: faft2b_\n",
      "PREDICT: kqw0w7o , LABEL: kqw0w7o\n",
      "PREDICT: tnn0e9o , LABEL: tnn0e9o\n",
      "PREDICT: ur_____ , LABEL: ur_____\n",
      "PREDICT: kanuf__ , LABEL: kanuf__\n",
      "PREDICT: mo7uvgp , LABEL: mo7uvgp\n",
      "PREDICT: sq_____ , LABEL: sq_____\n",
      "PREDICT: d3l____ , LABEL: d3l____\n",
      "PREDICT: 9uoc8a9 , LABEL: 9uoc8a9\n",
      "PREDICT: 14ep400 , LABEL: 14ep400\n",
      "PREDICT: tm_____ , LABEL: tm_____\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: hdp5xlc , LABEL: hdp5xlc\n",
      "PREDICT: 63sc___ , LABEL: 63sc___\n",
      "PREDICT: ggavc__ , LABEL: ggavc__\n",
      "PREDICT: 0u_____ , LABEL: 0u_____\n",
      "PREDICT: tp1____ , LABEL: tp1____\n",
      "PREDICT: 2k_____ , LABEL: 2k_____\n",
      "PREDICT: rp8____ , LABEL: rp8____\n",
      "PREDICT: x5kn5__ , LABEL: x5kn5__\n",
      "PREDICT: imcmab_ , LABEL: imcmab_\n",
      "PREDICT: 4r46f9_ , LABEL: 4r46f9_\n",
      "PREDICT: py53d9_ , LABEL: py53d9_\n",
      "PREDICT: bp_____ , LABEL: bp_____\n",
      "PREDICT: 56tt___ , LABEL: 56tt___\n",
      "PREDICT: 8tbvuk_ , LABEL: 8tbvuk_\n",
      "PREDICT: d9uvy5i , LABEL: d9uvy5i\n",
      "PREDICT: 3x82lj_ , LABEL: 3x82lj_\n",
      "PREDICT: pko____ , LABEL: pko____\n",
      "PREDICT: ff_____ , LABEL: ff_____\n",
      "PREDICT: xop9___ , LABEL: xop9___\n",
      "PREDICT: euxe___ , LABEL: euxe___\n",
      "PREDICT: qcn____ , LABEL: qcn____\n",
      "PREDICT: 54vwkxr , LABEL: 54vwkxr\n",
      "PREDICT: gk_____ , LABEL: gk_____\n",
      "PREDICT: xpg____ , LABEL: xpg____\n",
      "PREDICT: crqlc__ , LABEL: crqlc__\n",
      "PREDICT: oi87gb_ , LABEL: oi87gb_\n",
      "100.0\n",
      "100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'END TEST'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TEST\"\"\"\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2, c3, c4, c5, c6 \n",
    "\n",
    "def get_str(ch_arr):\n",
    "    ch_str = ''\n",
    "    for ch in ch_arr:\n",
    "        if ch == 'NONE':\n",
    "            ch_str = ch_str + '_'\n",
    "        else:\n",
    "            ch_str = ch_str + ch\n",
    "    return ch_str\n",
    "\n",
    "char_correct = 0\n",
    "word_correct = 0\n",
    "total = 0\n",
    "\n",
    "betternet.eval()\n",
    "lstm.eval()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "        char_count = 0\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.long()).cuda()\n",
    "        \n",
    "#         pred, feature = betternet(img)\n",
    "        pred = model(img, label_oh)\n",
    "\n",
    "        label_len = label[0]\n",
    "        pred = pred.squeeze(0)\n",
    "        label_oh = label_oh.squeeze(0)\n",
    "        \n",
    "        c0,c1,c2,c3,c4,c5,c6 = get_char_count(pred.squeeze()) \n",
    "        d0,d1,d2,d3,d4,d5,d6 = get_char_count(label_oh) \n",
    "         \n",
    "        c_arr = (c0, c1, c2, c3, c4, c5, c6)\n",
    "        d_arr = (d0, d1, d2, d3, d4, d5, d6)\n",
    "        \n",
    "        c = '%s%s%s%s%s%s%s' % c_arr\n",
    "        d = '%s%s%s%s%s%s%s' % d_arr\n",
    "        \n",
    "        c_str = get_str(c_arr)\n",
    "        d_str = get_str(d_arr)\n",
    "        \n",
    "        print('PREDICT:', c_str, ', LABEL:', d_str)\n",
    "    \n",
    "        char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "        char_correct += char_count\n",
    "\n",
    "        if(bool(str(label[0]) in str(c))):\n",
    "            word_correct+=1\n",
    "\n",
    "        total += 1\n",
    "       \n",
    "print(100/7*char_correct/total)\n",
    "print(100*word_correct/total)\n",
    "\"\"\"END TEST\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
