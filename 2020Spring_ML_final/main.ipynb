{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0zuYQzwiO8Z",
        "colab_type": "text"
      },
      "source": [
        "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri0oOICuC64e",
        "colab_type": "text"
      },
      "source": [
        "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJfG1l3RC_c3",
        "colab_type": "text"
      },
      "source": [
        "**For understanding of this work, please carefully look at given PPT file.**\n",
        "\n",
        "Note: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9yv4oGGDbmJ",
        "colab_type": "code",
        "outputId": "76b24c10-0f36-407e-9bb7-2c9ce3b5edff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import resnet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acvGcUAaEkxe",
        "colab_type": "text"
      },
      "source": [
        "Load datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPk4u8qGZHB",
        "colab_type": "code",
        "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "NONE = ['NONE'] # label for empty space\n",
        "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
        "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
        "MAX_CAPTCHA = 7\n",
        "\n",
        "print(ALL_CHAR_SET.index('NONE'))\n",
        "\n",
        "def encode(a):\n",
        "    onehot = [0]*ALL_CHAR_SET_LEN\n",
        "    idx = ALL_CHAR_SET.index(a)\n",
        "    onehot[idx] += 1\n",
        "    return onehot\n",
        "\n",
        "# modified dataset class\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
        "        self.path = img_path\n",
        "        self.label_path = label_path\n",
        "        if is_train: \n",
        "            self.img = os.listdir(self.path)[:1000]\n",
        "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
        "        else: \n",
        "            self.img = os.listdir(self.path)[:1000]\n",
        "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.max_length = MAX_CAPTCHA\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img[idx]\n",
        "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
        "        img = img.convert('L')\n",
        "        label = self.labels[idx]\n",
        "        label_oh = []\n",
        "        # one-hot for each character\n",
        "        for i in range(self.max_length):\n",
        "            if i < len(label):\n",
        "                label_oh += encode(label[i])\n",
        "            else:\n",
        "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
        "                label_oh += encode('NONE')\n",
        "            \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, np.array(label_oh), label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([160, 60]),\n",
        "    transforms.ToTensor(),\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4697c0a5-d24a-4e05-f226-14021b625f5e",
        "id": "EFtlQyubGJZb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"Loading DATA\"\"\"\n",
        "# Change to your own data foler path!\n",
        "gPath = '/content/drive/My Drive/final_projects/'\n",
        "\n",
        "train_ds = Mydataset(gPath+'data/train/', gPath+'data/train.txt',transform=transform)\n",
        "test_ds = Mydataset(gPath+'data/test/', gPath+'data/test.txt',False, transform)\n",
        "train_dl = DataLoader(train_ds, batch_size=128, num_workers=4)\n",
        "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka5SgX6VIWcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"To CUDA for local run\"\"\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#GPUID = '4' # define GPUID\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJaHW3wSENjY",
        "colab_type": "text"
      },
      "source": [
        "Problem 1: Design LSTM model for catcha image recognition. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac",
        "id": "rHEe3XmBFQHq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, cnn_dim, hidden_size, vocab_size, num_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        # define the properties\n",
        "        self.cnn_dim = cnn_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # lstm cell\n",
        "        self.lstm_cell = nn.LSTMCell(input_size=self.vocab_size, hidden_size=hidden_size)\n",
        "    \n",
        "        # output fully connected layer\n",
        "        self.fc_in = nn.Linear(in_features=self.cnn_dim, out_features=self.vocab_size)\n",
        "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
        "    \n",
        "        # embedding layer\n",
        "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.vocab_size)\n",
        "    \n",
        "        # activations\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    def forward(self, features, captions):\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        cnn_dim = features.size(1)\n",
        "\n",
        "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "    \n",
        "        # define the output tensor placeholder\n",
        "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).cuda()\n",
        "\n",
        "        # embed the captions\n",
        "        captions_embed = self.embed(captions)\n",
        "\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "        return outputs \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM2vL2PTFeEt",
        "colab_type": "text"
      },
      "source": [
        "Problem 2: \n",
        "\n",
        "*   1.Connect CNN model to the desinged LSTM model.\n",
        "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
        "\n",
        "\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwgpQ1aiFq2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\"\"\"ResNet\"\"\"\n",
        "#CNN\n",
        "betternet = resnet.resnet18(pretrained=False)\n",
        "betternet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "betternet.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)\n",
        "betternet = betternet.to(device)\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "\n",
        "       \n",
        "# LSTM\n",
        "cnn_dim=512 #resnet18-512\n",
        "hidden_size=8\n",
        "vocab_size=37 #ALL_CHAR_SET_LEN\n",
        "lstm = LSTM(cnn_dim=cnn_dim, hidden_size=hidden_size, vocab_size=vocab_size)\n",
        "lstm = lstm.to(device)\n",
        "\n",
        "# loss, optimizer\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "cnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoeTIkXjHJIE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0uCexwRHsNz",
        "colab_type": "text"
      },
      "source": [
        "Problem3: Find hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibfVzKZeH1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TRAINING\"\"\"\n",
        "print_interval = 15\n",
        "max_epoch = 1000\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for step, i in enumerate(train_dl):\n",
        "        img, label_oh, label = i\n",
        "        img = Variable(img).cuda()\n",
        "        label_oh = Variable(label_oh.float()).cuda()\n",
        "        batch_size, _ = label_oh.shape\n",
        "        pred, feature = betternet(img)\n",
        "        loss = loss_func(pred, label_oh)\n",
        "        cnn_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        cnn_optim.step()\n",
        "##############################################################################\n",
        "#                          IMPLEMENT YOUR CODE                               #\n",
        "##############################################################################\n",
        "\n",
        "##############################################################################\n",
        "#                          END OF YOUR CODE                                  #\n",
        "##############################################################################\n",
        "        if (step+1)%print_interval == 0:\n",
        "            print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_uKOpe8IGJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TEST\"\"\"\n",
        "def get_char_count(arg1):\n",
        "    c0 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
        "    c1 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
        "    c2 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
        "    c3 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
        "    c4 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
        "    c5 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
        "    c6 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
        "    return c0, c1, c2,c3, c4, c5, c6 \n",
        " \n",
        "\n",
        "\n",
        "char_correct = 0\n",
        "word_correct = 0\n",
        "total = 0\n",
        "\n",
        "betternet.eval()\n",
        "lstm.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for step, (img, label_oh, label) in enumerate(test_dl):\n",
        "        char_count =0\n",
        "        img = Variable(img).cuda()\n",
        "        label_oh = Variable(label_oh.float()).cuda()\n",
        "        pred, feature = betternet(img)\n",
        "\n",
        "        label_len = label[0]\n",
        "        pred = pred.squeeze(0)\n",
        "        label_oh = label_oh.squeeze(0)\n",
        "        \n",
        "        c0,c1,c2,c3,c4,c5,c6 = get_char_count(pred.squeeze()) \n",
        "        d0,d1,d2,d3,d4,d5,d6 = get_char_count(label_oh) \n",
        "         \n",
        "        c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
        "        d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
        "    \n",
        "        char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
        "        char_correct += char_count\n",
        "\n",
        "        if(bool(str(label[0]) in str(c))):\n",
        "            word_correct+=1\n",
        "\n",
        "        total += 1\n",
        "       \n",
        "print(100/7*char_correct/total)\n",
        "print(100*word_correct/total)\n",
        "\"\"\"END TEST\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}