{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6j5WcA3GbSk"
   },
   "source": [
    "# M2608.001300 기계학습 기초 및 전기정보 응용<br> Assignment 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei9BMeksGbSn"
   },
   "source": [
    "## Dataset load & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vlb19coAGbSo"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xV9Z9RPMGbSt",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.loadtxt('data.csv', delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "label_mask = np.equal(y, 1)\n",
    "\n",
    "plt.scatter(X[:, 0][label_mask], X[:, 1][label_mask], color='red')\n",
    "plt.scatter(X[:, 0][~label_mask], X[:, 1][~label_mask], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwcWe3pDGbSy"
   },
   "source": [
    "## Problem 1-1. sklearn model로 Logistic Regression 모델 train 시켜보기\n",
    "scikit-learn library의 LogisticRegression 클래스를 이용해 train 시켜 보세요. <br>\n",
    "클래스 인자 및 사용법에 관해서는 scikit-learn 홈페이지의 설명을 참고해 주세요. <br>\n",
    "(참고: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONWQ_Q5yGbS0"
   },
   "outputs": [],
   "source": [
    "def learn_and_return_weights(X, y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    # YOUR CODE COMES HERE\n",
    "    # w: coefficient of the model to input features,\n",
    "    # b: bias of the model\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkQB55lkGbS3"
   },
   "outputs": [],
   "source": [
    "def plot_data_and_weights(X, y, w, b):\n",
    "    plt.scatter(X[:, 0][label_mask], X[:, 1][label_mask], color='red')\n",
    "    plt.scatter(X[:, 0][~label_mask], X[:, 1][~label_mask], color='blue')\n",
    "\n",
    "    x_lin = np.arange(20, 70)\n",
    "    y_lin = -(0.5 + b + w[0] * x_lin) / w[1]\n",
    "\n",
    "    plt.plot(x_lin, y_lin, color='black');\n",
    "    plt.show()\n",
    "\n",
    "w, b = learn_and_return_weights(X, y)\n",
    "plot_data_and_weights(X, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKYz83ecGbS6"
   },
   "source": [
    "## Problem 1-2. numpy로 Logistic Regression 짜보기\n",
    "scikit-learn library를 사용하지 않고 Logistic Regression을 구현해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGTRLxvsGbS7"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # YOUR CODE COMES HERE\n",
    "     \n",
    "\n",
    "def binary_cross_entropy_loss(y_pred, target):\n",
    "    # YOUR CODE COMES HERE\n",
    "\n",
    "def learn_and_return_weights_numpy(X, Y, lr=.01, iter=100000):\n",
    "    # YOUR CODE COMES HERE\n",
    "    # w: coefficient of the model to input features,\n",
    "    # b: bias of the model\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryO_ItqRGbS_"
   },
   "outputs": [],
   "source": [
    "w, b = learn_and_return_weights_numpy(X, y)\n",
    "plot_data_and_weights(X, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTPkme9rGbTC"
   },
   "source": [
    "## Problem 2. sklearn model로 Logistic Regression 모델 train 시켜보기 + regularizer 사용하기\n",
    "scikit-learn library의 Logistic Regression 에 대한 API문서를 읽어보고,<br>\n",
    "L1-regularization을 사용할 때와 L2-regularization을 사용할 때의 weight의 변화를 살펴보세요. <br>\n",
    "(참고: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUR-wC9CGbTC"
   },
   "outputs": [],
   "source": [
    "def learn_and_return_weights_l1_regularized(X, y):    \n",
    "    # YOUR CODE COMES HERE\n",
    "    return w, b\n",
    "\n",
    "def learn_and_return_weights_l2_regularized(X, y):    \n",
    "    # YOUR CODE COMES HERE\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7gpEX1YGbTF"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    D = 1000\n",
    "    N = 80\n",
    "\n",
    "    X = np.random.random((N, D))\n",
    "    w = np.zeros(D)\n",
    "    w[0] = 1\n",
    "    w[1] = 1\n",
    "    \n",
    "    e = np.random.random(N) - 0.5\n",
    "    \n",
    "    y_score = np.dot(X, w)\n",
    "    y_score_median = np.median(y_score)\n",
    "    print(y_score.max(), y_score.min(), y_score_median)\n",
    "    \n",
    "    # y_score += 0.01 * e\n",
    "    y = y_score >= y_score_median\n",
    "    y = y.astype(np.int32)\n",
    "    \n",
    "    return (X[:N // 2], y[:N // 2]), (X[N // 2:], y[N // 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cG6nG0fGbTI"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_dataset()\n",
    "\n",
    "w_l1, b_l1 = learn_and_return_weights_l1_regularized(x_train, y_train)\n",
    "w_l2, b_l2 = learn_and_return_weights_l2_regularized(x_train, y_train)\n",
    "\n",
    "print(w_l1[:5])\n",
    "print(w_l2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "v_DaRCDGHJZ5"
   },
   "source": [
    "## Problem 3-1. Logistic Regression으로 multi-class classification 하기: API 활용하기\n",
    "scikit-learn library의 Logistic Regression API를 활용하면 multi-class classification을 간단하게 수행할 수 있습니다.<br>\n",
    "MNIST dataset에 대해 multi-class classification을 위한 Logistic Regression 모델을 학습시키고, test data에 대한 accuracy를 계산해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJNyQWnuGbTL"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    from keras.datasets import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape((-1, 28 * 28)).astype(np.float32)\n",
    "    x_test = x_test.reshape((-1, 28 * 28)).astype(np.float32)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "(x_train, y_train), (x_test, y_test) = get_dataset()\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Hi81olzGbTT"
   },
   "outputs": [],
   "source": [
    "def learn_mul(X, y):\n",
    "    # YOUR CODE COMES HERE\n",
    "    return lr\n",
    "\n",
    "def inference_mul(x, lr):\n",
    "    # YOUR CODE COMES HERE\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfdTZNUYGbTW"
   },
   "outputs": [],
   "source": [
    "model = learn_mul(x_train, y_train)\n",
    "preds = inference_mul(x_test, model)\n",
    "accuracy = np.sum(preds == y_test) / y_test.shape[0]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2OLcsStrGbTK"
   },
   "source": [
    "## Problem 3-2. Logistic Regression으로 multi-class classification 하기: Transformation to Binary\n",
    "\n",
    "Logistic Regression은 기본적으로 binary classifier 입니다. 즉, input *X*를 2개의 class로 밖에 분류하지 못합니다.<br>\n",
    "하지만, 이같은 Logistic Regression 모델을 연달아 사용한다면 data를 여러 class로 분류할 수도 있습니다.<br>\n",
    "(참고: https://en.wikipedia.org/wiki/Multiclass_classification#Transformation_to_binary)\n",
    "\n",
    "MNIST dataset을 이용하여 (class 수) 개의 Binary classifier (Logistic Regression)를 'lrs'의 각 원소에 저장한 뒤,<br>\n",
    "학습시킨 모델들을 이용하여 test data에 대한 accuracy를 계산해 보세요.<br>\n",
    "(각 모델의 training iteration은 10회면 충분합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlYDigjwGbTO"
   },
   "outputs": [],
   "source": [
    "def learn_mul2bin(X, y):\n",
    "    lrs = []\n",
    "    ordinal = lambda n: \"%d%s\" % (n,\"tsnrhtdd\"[(n/10%10!=1)*(n%10<4)*n%10::4])\n",
    "    for i in range(num_classes):\n",
    "        print('training %s classifier'%(ordinal(i+1)))\n",
    "        # YOUR CODE COMES HERE\n",
    "    return lrs\n",
    "\n",
    "def inference_mul2bin(x, lrs):\n",
    "    # YOUR CODE COMES HERE\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKF3C-4OGbTR"
   },
   "outputs": [],
   "source": [
    "models = learn_mul2bin(x_train, y_train)\n",
    "preds = np.array([inference_mul2bin(x, models) for x in x_test])\n",
    "accuracy = np.sum(preds == y_test) / y_test.shape[0]\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "AS1-Logistic_Regression.ipynb",
   "provenance": [
    {
     "file_id": "1br9I49jKldloi3aOJ6HPGtq3RLU9h5ft",
     "timestamp": 1583728216996
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
